{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from messis.messis import Messis\n",
    "from safetensors import safe_open\n",
    "from transformers import PretrainedConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Messis from Huggingface ðŸ¤— for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvokeller/Library/Caches/pypoetry/virtualenvs/messis-bV8Bs8aq-py3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af45c5eb773462ca42a8eec540cb222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d135e8698434b7b83142a64adc982cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TemporalViTEncoder | Warning: Unexpected keys in the state dict: ['mask_token', 'decoder_pos_embed', 'decoder_embed.weight', 'decoder_embed.bias', 'decoder_blocks.0.norm1.weight', 'decoder_blocks.0.norm1.bias', 'decoder_blocks.0.attn.qkv.weight', 'decoder_blocks.0.attn.qkv.bias', 'decoder_blocks.0.attn.proj.weight', 'decoder_blocks.0.attn.proj.bias', 'decoder_blocks.0.norm2.weight', 'decoder_blocks.0.norm2.bias', 'decoder_blocks.0.mlp.fc1.weight', 'decoder_blocks.0.mlp.fc1.bias', 'decoder_blocks.0.mlp.fc2.weight', 'decoder_blocks.0.mlp.fc2.bias', 'decoder_blocks.1.norm1.weight', 'decoder_blocks.1.norm1.bias', 'decoder_blocks.1.attn.qkv.weight', 'decoder_blocks.1.attn.qkv.bias', 'decoder_blocks.1.attn.proj.weight', 'decoder_blocks.1.attn.proj.bias', 'decoder_blocks.1.norm2.weight', 'decoder_blocks.1.norm2.bias', 'decoder_blocks.1.mlp.fc1.weight', 'decoder_blocks.1.mlp.fc1.bias', 'decoder_blocks.1.mlp.fc2.weight', 'decoder_blocks.1.mlp.fc2.bias', 'decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_blocks.3.norm1.weight', 'decoder_blocks.3.norm1.bias', 'decoder_blocks.3.attn.qkv.weight', 'decoder_blocks.3.attn.qkv.bias', 'decoder_blocks.3.attn.proj.weight', 'decoder_blocks.3.attn.proj.bias', 'decoder_blocks.3.norm2.weight', 'decoder_blocks.3.norm2.bias', 'decoder_blocks.3.mlp.fc1.weight', 'decoder_blocks.3.mlp.fc1.bias', 'decoder_blocks.3.mlp.fc2.weight', 'decoder_blocks.3.mlp.fc2.bias', 'decoder_blocks.4.norm1.weight', 'decoder_blocks.4.norm1.bias', 'decoder_blocks.4.attn.qkv.weight', 'decoder_blocks.4.attn.qkv.bias', 'decoder_blocks.4.attn.proj.weight', 'decoder_blocks.4.attn.proj.bias', 'decoder_blocks.4.norm2.weight', 'decoder_blocks.4.norm2.bias', 'decoder_blocks.4.mlp.fc1.weight', 'decoder_blocks.4.mlp.fc1.bias', 'decoder_blocks.4.mlp.fc2.weight', 'decoder_blocks.4.mlp.fc2.bias', 'decoder_blocks.5.norm1.weight', 'decoder_blocks.5.norm1.bias', 'decoder_blocks.5.attn.qkv.weight', 'decoder_blocks.5.attn.qkv.bias', 'decoder_blocks.5.attn.proj.weight', 'decoder_blocks.5.attn.proj.bias', 'decoder_blocks.5.norm2.weight', 'decoder_blocks.5.norm2.bias', 'decoder_blocks.5.mlp.fc1.weight', 'decoder_blocks.5.mlp.fc1.bias', 'decoder_blocks.5.mlp.fc2.weight', 'decoder_blocks.5.mlp.fc2.bias', 'decoder_blocks.6.norm1.weight', 'decoder_blocks.6.norm1.bias', 'decoder_blocks.6.attn.qkv.weight', 'decoder_blocks.6.attn.qkv.bias', 'decoder_blocks.6.attn.proj.weight', 'decoder_blocks.6.attn.proj.bias', 'decoder_blocks.6.norm2.weight', 'decoder_blocks.6.norm2.bias', 'decoder_blocks.6.mlp.fc1.weight', 'decoder_blocks.6.mlp.fc1.bias', 'decoder_blocks.6.mlp.fc2.weight', 'decoder_blocks.6.mlp.fc2.bias', 'decoder_blocks.7.norm1.weight', 'decoder_blocks.7.norm1.bias', 'decoder_blocks.7.attn.qkv.weight', 'decoder_blocks.7.attn.qkv.bias', 'decoder_blocks.7.attn.proj.weight', 'decoder_blocks.7.attn.proj.bias', 'decoder_blocks.7.norm2.weight', 'decoder_blocks.7.norm2.bias', 'decoder_blocks.7.mlp.fc1.weight', 'decoder_blocks.7.mlp.fc1.bias', 'decoder_blocks.7.mlp.fc2.weight', 'decoder_blocks.7.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias', 'decoder_pred.weight', 'decoder_pred.bias']\n",
      "TemporalViTEncoder | Loaded pretrained weights from './prithvi/models/Prithvi_100M.pt' (pt file).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4e7bb9af824cfa897001fc90d27b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = PretrainedConfig.from_pretrained('crop-classification/messis')\n",
    "model = Messis.from_pretrained('crop-classification/messis', cache_dir='./hf_cache/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "```python\n",
    "Messis(\n",
    "  (model): HierarchicalClassifier(\n",
    "    (prithvi): TemporalViTEncoder(\n",
    "      (patch_embed): PatchEmbed(\n",
    "        (proj): Conv3d(6, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16))\n",
    "        (norm): Identity()\n",
    "      )\n",
    "      (blocks): ModuleList(\n",
    "        (0-11): 12 x Block(\n",
    "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "          (attn): Attention(\n",
    "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
    "            (q_norm): Identity()\n",
    "            (k_norm): Identity()\n",
    "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
    "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
    "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
    "          )\n",
    "          (ls1): Identity()\n",
    "          (drop_path1): Identity()\n",
    "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "          (mlp): Mlp(\n",
    "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
    "            (act): GELU(approximate='none')\n",
    "            (drop1): Dropout(p=0.0, inplace=False)\n",
    "            (norm): Identity()\n",
    "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
    "            (drop2): Dropout(p=0.0, inplace=False)\n",
    "          )\n",
    "          (ls2): Identity()\n",
    "          (drop_path2): Identity()\n",
    "        )\n",
    "      )\n",
    "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "    )\n",
    "    (neck): ConvTransformerTokensToEmbeddingNeck(\n",
    "      (fpn1): Sequential(\n",
    "        (0): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
    "        (1): Norm2d(\n",
    "          (ln): LayerNorm((2304,), eps=1e-06, elementwise_affine=True)\n",
    "        )\n",
    "        (2): GELU(approximate='none')\n",
    "        (3): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
    "      )\n",
    "      (fpn2): Sequential(\n",
    "        (0): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
    "        (1): Norm2d(\n",
    "          (ln): LayerNorm((2304,), eps=1e-06, elementwise_affine=True)\n",
    "        )\n",
    "        (2): GELU(approximate='none')\n",
    "        (3): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
    "      )\n",
    "    )\n",
    "    (heads): ModuleDict(\n",
    "      (tier1): HierarchicalFCNHead(\n",
    "        (convs): Sequential(\n",
    "          (0): ConvModule(\n",
    "            (conv): Conv2d(2304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (relu): ReLU(inplace=True)\n",
    "          )\n",
    "        )\n",
    "        (conv_seg): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
    "        (dropout): Dropout2d(p=0.1, inplace=False)\n",
    "      )\n",
    "      (tier2): HierarchicalFCNHead(\n",
    "        (convs): Sequential(\n",
    "          (0): ConvModule(\n",
    "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (relu): ReLU(inplace=True)\n",
    "          )\n",
    "        )\n",
    "        (conv_seg): Conv2d(256, 17, kernel_size=(1, 1), stride=(1, 1))\n",
    "        (dropout): Dropout2d(p=0.1, inplace=False)\n",
    "      )\n",
    "      (tier3): HierarchicalFCNHead(\n",
    "        (convs): Sequential(\n",
    "          (0): ConvModule(\n",
    "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (relu): ReLU(inplace=True)\n",
    "          )\n",
    "        )\n",
    "        (conv_seg): Conv2d(256, 49, kernel_size=(1, 1), stride=(1, 1))\n",
    "        (dropout): Dropout2d(p=0.1, inplace=False)\n",
    "      )\n",
    "    )\n",
    "    (refinement_head): LabelRefinementHead(\n",
    "      (cnn_layers): Sequential(\n",
    "        (0): Conv2d(72, 128, kernel_size=(1, 1), stride=(1, 1))\n",
    "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (2): ReLU(inplace=True)\n",
    "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (5): ReLU(inplace=True)\n",
    "        (6): Dropout(p=0.5, inplace=False)\n",
    "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (9): ReLU(inplace=True)\n",
    "        (10): Conv2d(128, 49, kernel_size=(1, 1), stride=(1, 1))\n",
    "        (11): Dropout(p=0.5, inplace=False)\n",
    "      )\n",
    "    )\n",
    "    (loss_func): CrossEntropyLoss()\n",
    "  )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Messis(\n",
       "  (model): HierarchicalClassifier(\n",
       "    (prithvi): TemporalViTEncoder(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv3d(6, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (neck): ConvTransformerTokensToEmbeddingNeck(\n",
       "      (fpn1): Sequential(\n",
       "        (0): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Norm2d(\n",
       "          (ln): LayerNorm((2304,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (fpn2): Sequential(\n",
       "        (0): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): Norm2d(\n",
       "          (ln): LayerNorm((2304,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): ConvTranspose2d(2304, 2304, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (heads): ModuleDict(\n",
       "      (tier1): HierarchicalFCNHead(\n",
       "        (convs): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv2d(2304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_seg): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "      )\n",
       "      (tier2): HierarchicalFCNHead(\n",
       "        (convs): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_seg): Conv2d(256, 17, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "      )\n",
       "      (tier3): HierarchicalFCNHead(\n",
       "        (convs): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_seg): Conv2d(256, 49, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (refinement_head): LabelRefinementHead(\n",
       "      (cnn_layers): Sequential(\n",
       "        (0): Conv2d(72, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Dropout(p=0.5, inplace=False)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (9): ReLU(inplace=True)\n",
       "        (10): Conv2d(128, 49, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (11): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â TODO: Implement inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone Total/Trainable Parameters: 86,689,536/0\n",
      "Neck Total/Trainable Parameters: 84,953,088/84,953,088\n",
      "HierarchicalFCNHead Total/Trainable Parameters: 6,508,104/6,508,104\n",
      "RefinementHead Total/Trainable Parameters: 311,601/311,601\n"
     ]
    }
   ],
   "source": [
    "#Â model param info\n",
    "backbone = model.model.prithvi\n",
    "neck = model.model.neck\n",
    "decode_head = model.model.heads\n",
    "auxiliary_head = model.model.refinement_head\n",
    "\n",
    "def count_parameters(model_part):\n",
    "    total_params = sum(p.numel() for p in model_part.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model_part.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "backbone_params, backbone_trainable = count_parameters(backbone)\n",
    "neck_params, neck_trainable = count_parameters(neck)\n",
    "decode_head_params, decode_head_trainable = count_parameters(decode_head)\n",
    "auxiliary_head_params, auxiliary_head_trainable = count_parameters(auxiliary_head)\n",
    "\n",
    "print(f\"Backbone Total/Trainable Parameters: {backbone_params:,}/{backbone_trainable:,}\")\n",
    "print(f\"Neck Total/Trainable Parameters: {neck_params:,}/{neck_trainable:,}\")\n",
    "print(f\"HierarchicalFCNHead Total/Trainable Parameters: {decode_head_params:,}/{decode_head_trainable:,}\")\n",
    "print(f\"RefinementHead Total/Trainable Parameters: {auxiliary_head_params:,}/{auxiliary_head_trainable:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate weights loading from .safetensors checkpoint\n",
    "\n",
    "### Expectation: should initalize the TemporalViTEncoder from the .safetensors checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7b1002a1944fb8a5cb9dbeedc68f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/708 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TemporalViTEncoder | Warning: Unexpected keys in the state dict: ['mask_token', 'decoder_pos_embed', 'decoder_embed.weight', 'decoder_embed.bias', 'decoder_blocks.0.norm1.weight', 'decoder_blocks.0.norm1.bias', 'decoder_blocks.0.attn.qkv.weight', 'decoder_blocks.0.attn.qkv.bias', 'decoder_blocks.0.attn.proj.weight', 'decoder_blocks.0.attn.proj.bias', 'decoder_blocks.0.norm2.weight', 'decoder_blocks.0.norm2.bias', 'decoder_blocks.0.mlp.fc1.weight', 'decoder_blocks.0.mlp.fc1.bias', 'decoder_blocks.0.mlp.fc2.weight', 'decoder_blocks.0.mlp.fc2.bias', 'decoder_blocks.1.norm1.weight', 'decoder_blocks.1.norm1.bias', 'decoder_blocks.1.attn.qkv.weight', 'decoder_blocks.1.attn.qkv.bias', 'decoder_blocks.1.attn.proj.weight', 'decoder_blocks.1.attn.proj.bias', 'decoder_blocks.1.norm2.weight', 'decoder_blocks.1.norm2.bias', 'decoder_blocks.1.mlp.fc1.weight', 'decoder_blocks.1.mlp.fc1.bias', 'decoder_blocks.1.mlp.fc2.weight', 'decoder_blocks.1.mlp.fc2.bias', 'decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_blocks.3.norm1.weight', 'decoder_blocks.3.norm1.bias', 'decoder_blocks.3.attn.qkv.weight', 'decoder_blocks.3.attn.qkv.bias', 'decoder_blocks.3.attn.proj.weight', 'decoder_blocks.3.attn.proj.bias', 'decoder_blocks.3.norm2.weight', 'decoder_blocks.3.norm2.bias', 'decoder_blocks.3.mlp.fc1.weight', 'decoder_blocks.3.mlp.fc1.bias', 'decoder_blocks.3.mlp.fc2.weight', 'decoder_blocks.3.mlp.fc2.bias', 'decoder_blocks.4.norm1.weight', 'decoder_blocks.4.norm1.bias', 'decoder_blocks.4.attn.qkv.weight', 'decoder_blocks.4.attn.qkv.bias', 'decoder_blocks.4.attn.proj.weight', 'decoder_blocks.4.attn.proj.bias', 'decoder_blocks.4.norm2.weight', 'decoder_blocks.4.norm2.bias', 'decoder_blocks.4.mlp.fc1.weight', 'decoder_blocks.4.mlp.fc1.bias', 'decoder_blocks.4.mlp.fc2.weight', 'decoder_blocks.4.mlp.fc2.bias', 'decoder_blocks.5.norm1.weight', 'decoder_blocks.5.norm1.bias', 'decoder_blocks.5.attn.qkv.weight', 'decoder_blocks.5.attn.qkv.bias', 'decoder_blocks.5.attn.proj.weight', 'decoder_blocks.5.attn.proj.bias', 'decoder_blocks.5.norm2.weight', 'decoder_blocks.5.norm2.bias', 'decoder_blocks.5.mlp.fc1.weight', 'decoder_blocks.5.mlp.fc1.bias', 'decoder_blocks.5.mlp.fc2.weight', 'decoder_blocks.5.mlp.fc2.bias', 'decoder_blocks.6.norm1.weight', 'decoder_blocks.6.norm1.bias', 'decoder_blocks.6.attn.qkv.weight', 'decoder_blocks.6.attn.qkv.bias', 'decoder_blocks.6.attn.proj.weight', 'decoder_blocks.6.attn.proj.bias', 'decoder_blocks.6.norm2.weight', 'decoder_blocks.6.norm2.bias', 'decoder_blocks.6.mlp.fc1.weight', 'decoder_blocks.6.mlp.fc1.bias', 'decoder_blocks.6.mlp.fc2.weight', 'decoder_blocks.6.mlp.fc2.bias', 'decoder_blocks.7.norm1.weight', 'decoder_blocks.7.norm1.bias', 'decoder_blocks.7.attn.qkv.weight', 'decoder_blocks.7.attn.qkv.bias', 'decoder_blocks.7.attn.proj.weight', 'decoder_blocks.7.attn.proj.bias', 'decoder_blocks.7.norm2.weight', 'decoder_blocks.7.norm2.bias', 'decoder_blocks.7.mlp.fc1.weight', 'decoder_blocks.7.mlp.fc1.bias', 'decoder_blocks.7.mlp.fc2.weight', 'decoder_blocks.7.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias', 'decoder_pred.weight', 'decoder_pred.bias']\n",
      "TemporalViTEncoder | Loaded pretrained weights from './prithvi/models/Prithvi_100M.pt' (pt file).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df70fe896f8465f98217bb61e821268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Â load the config from HF\n",
    "model = Messis.from_pretrained('crop-classification/messis', cache_dir='./hf_cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0125, -0.0556, -0.1178,  ...,  0.0313,  0.0138, -0.0571],\n",
       "        [ 0.0589,  0.0056,  0.0024,  ...,  0.0440, -0.0671, -0.0293],\n",
       "        [ 0.0293,  0.0323,  0.1029,  ..., -0.0538,  0.0750, -0.0168],\n",
       "        ...,\n",
       "        [-0.0691,  0.0143, -0.0396,  ...,  0.0110,  0.0111,  0.0053],\n",
       "        [-0.0213, -0.0075,  0.0199,  ...,  0.0025, -0.0709,  0.0018],\n",
       "        [-0.0829,  0.0343,  0.0246,  ...,  0.0382, -0.0153,  0.0063]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â get first few weights from model.model.prithvi:\n",
    "messis_from_pretrained_weights = model.model.prithvi.blocks[0].attn.qkv.weight\n",
    "messis_from_pretrained_weights = messis_from_pretrained_weights.to(0)\n",
    "messis_from_pretrained_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation: these weights directly loaded from Prithvi .pt checkpoint should be the ones present when loading using pretrained=\"./prithvi/models/Prithvi_100M.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0119, -0.0555, -0.1045,  ...,  0.0349,  0.0202, -0.0542],\n",
       "        [ 0.0572,  0.0054, -0.0105,  ...,  0.0428, -0.0756, -0.0308],\n",
       "        [ 0.0295,  0.0335,  0.1179,  ..., -0.0521,  0.0840, -0.0158],\n",
       "        ...,\n",
       "        [-0.0553,  0.0117, -0.0415,  ...,  0.0126,  0.0132,  0.0127],\n",
       "        [-0.0171, -0.0060,  0.0185,  ...,  0.0019, -0.0689,  0.0041],\n",
       "        [-0.0943,  0.0341,  0.0188,  ...,  0.0410, -0.0187,  0.0078]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pt file independently ./prithvi/models/Prithvi_100M.pt\n",
    "weights = torch.load('./prithvi/models/Prithvi_100M.pt')\n",
    "weights.keys()\n",
    "\n",
    "original_prithvi_weights = weights['blocks.0.attn.qkv.weight']\n",
    "\n",
    "#Â to GPU\n",
    "original_prithvi_weights = original_prithvi_weights.to(0)\n",
    "original_prithvi_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights in the safetensors checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0125, -0.0556, -0.1178,  ...,  0.0313,  0.0138, -0.0571],\n",
      "        [ 0.0589,  0.0056,  0.0024,  ...,  0.0440, -0.0671, -0.0293],\n",
      "        [ 0.0293,  0.0323,  0.1029,  ..., -0.0538,  0.0750, -0.0168]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "path = \"hf_cache/models--crop-classification--messis/snapshots/4f9a588c51c8dbaf2dcff67223d5908e4bf710a2/model.safetensors\"\n",
    "\n",
    "hf_safetensors_weights = None\n",
    "\n",
    "with safe_open(path, framework=\"pt\", device=0) as f:\n",
    "    weights_safetensors = tensor_slice = f.get_slice(\"model.prithvi.blocks.0.attn.qkv.weight\")\n",
    "    print(tensor_slice[:3])\n",
    "\n",
    "    hf_safetensors_weights = tensor_slice[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hf_safetensors_weights), type(messis_from_pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if the weights were loaded as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is from_pt_weights_inizialized = from_prithvi_weights False\n",
      " Is from_pt_weights_inizialized = from_safetensors_weights True\n"
     ]
    }
   ],
   "source": [
    "# for the case that the backbone is was trained, we expect:\n",
    "#Â messis_from_pretrained_weights != original_prithvi_weights\n",
    "# messis_from_pretrained_weights == hf_safetensors_weights\n",
    "print(f\" Is from_pt_weights_inizialized = from_prithvi_weights {torch.allclose(messis_from_pretrained_weights, original_prithvi_weights)}\") # False\n",
    "print(f\" Is from_pt_weights_inizialized = from_safetensors_weights {torch.allclose(messis_from_pretrained_weights, hf_safetensors_weights)}\") # True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messis-twAw6TW6-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
