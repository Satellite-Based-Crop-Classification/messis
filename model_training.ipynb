{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818a726f13ab4dcdb3b4eb65af162be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"model_training.ipynb\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"MPLBACKEND\"] = \"agg\"\n",
    "\n",
    "import yaml\n",
    "import dvc.api\n",
    "import wandb\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from messis.messis import Messis, LogConfusionMatrix, LogMessisMetrics\n",
    "from messis.dataloader import GeospatialDataModule\n",
    "\n",
    "params = dvc.api.params_show()\n",
    "\n",
    "HF_MODEL_URL = \"https://huggingface.co/crop-classification/messis\"\n",
    "\n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [1, 2, 3, 4]\n",
      "[1] [0, 2, 3, 4]\n",
      "[2] [0, 1, 3, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] [0, 1, 2, 4]\n",
      "[4] [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # from multiprocessing import freeze_support\n",
    "    # freeze_support() # for Windows support\n",
    "\n",
    "    with open(params['paths']['chips_stats'], 'r') as file:\n",
    "        chips_stats = yaml.safe_load(file)\n",
    "\n",
    "    experiment_group = 'exp-7-label-hierarchy'\n",
    "    experiment_name_short = 'test'\n",
    "    # Hyperparameters\n",
    "    hparams = {\n",
    "        'experiment_name': f'{experiment_group}-{experiment_name_short}',\n",
    "        'name': experiment_name_short,\n",
    "        'experiment_group': experiment_group,\n",
    "        'img_size': params['chip_size'],\n",
    "        'patch_size': 16,\n",
    "        'num_frames': 3,\n",
    "        'bands': [0, 1, 2, 3, 4, 5],\n",
    "        'debug': False,\n",
    "        'lr': 1e-3,\n",
    "        'optimizer': 'Adam',\n",
    "        'optimizer_weight_decay': None,\n",
    "        'optimizer_momentum': None,\n",
    "        'batch_size': 16, # up to 16 on server0111\n",
    "        'accumulate_grad_batches': 1, # when no accumulation, choose 1\n",
    "        'early_stopping_metric': 'val_loss',\n",
    "        'early_stopping_mode': 'min', # 'min' or 'max\n",
    "        'early_stopping_patience': 10,\n",
    "        'max_epochs': 400,\n",
    "        'dropout_p': 0.1,\n",
    "        'backbone_weights_path': './prithvi/models/Prithvi_100M.pt',\n",
    "        'freeze_backbone': True,\n",
    "        'subsets': {\n",
    "            'train': 4,\n",
    "            'val': 2,\n",
    "        },\n",
    "        'test_folds': [5],\n",
    "        'heads_spec': {\n",
    "            'tier1': {\n",
    "                'type': 'HierarchicalFCNHead',\n",
    "                'loss_weight': 1,\n",
    "                'num_classes_to_predict': chips_stats['num_classes_tier1'],\n",
    "                'target_idx': 0\n",
    "            },\n",
    "            'tier2': {\n",
    "                'type': 'HierarchicalFCNHead',\n",
    "                'loss_weight': 1,\n",
    "                'num_classes_to_predict': chips_stats['num_classes_tier2'],\n",
    "                'target_idx': 1\n",
    "            },\n",
    "            'tier3': {\n",
    "                'type': 'HierarchicalFCNHead',\n",
    "                'loss_weight': 1,\n",
    "                'num_classes_to_predict': chips_stats['num_classes_tier3'],\n",
    "                'target_idx': 2\n",
    "            },\n",
    "            'tier3_refinement_head': {\n",
    "                'type': 'LabelRefinementHead',\n",
    "                'loss_weight': 1,\n",
    "                'num_classes_to_predict': chips_stats['num_classes_tier3'],\n",
    "                'target_idx': 2\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    remaining_folds = list(set(range(params['number_of_folds'])) - set(hparams['test_folds']))\n",
    "\n",
    "    for fold in remaining_folds:\n",
    "        hparams['val_folds'] = [fold]\n",
    "        hparams['train_folds'] = list(set(remaining_folds) - set(hparams['val_folds']))\n",
    "\n",
    "        # Create a W&B logger\n",
    "        wandb_logger = WandbLogger(\n",
    "            name=f\"{hparams['experiment_name']}-{fold}\",\n",
    "            entity='crop-classification',\n",
    "            project='messis',\n",
    "            log_model=False)\n",
    "        wandb_logger.experiment.config['dvc'] = params\n",
    "\n",
    "        model = Messis(hparams)\n",
    "\n",
    "        data_module = GeospatialDataModule(\n",
    "            data_dir='./data/', \n",
    "            train_folds=hparams['train_folds'],\n",
    "            val_folds=hparams['val_folds'],\n",
    "            test_folds=hparams['test_folds'],\n",
    "            batch_size=hparams.get('batch_size', 4), \n",
    "            num_workers=1,      # 1 worker is enough for this dataset\n",
    "            debug=False, \n",
    "            subsets=hparams.get('subsets', None)\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=hparams.get('early_stopping_metric', 'val_loss'), # Metric to monitor\n",
    "            mode=hparams.get('early_stopping_mode', 'min'), # 'min' or 'max'\n",
    "            patience=hparams['early_stopping_patience'], # Number of epochs to wait for improvement\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            logger=wandb_logger,\n",
    "            log_every_n_steps=16,\n",
    "            profiler=\"simple\",\n",
    "            callbacks=[\n",
    "                LogMessisMetrics  (hparams, params['paths']['dataset_info'], debug=False),\n",
    "                LogConfusionMatrix(hparams, params['paths']['dataset_info'], debug=False),\n",
    "                early_stopping\n",
    "            ],\n",
    "            accumulate_grad_batches=hparams['accumulate_grad_batches'],  # Gradient accumulation\n",
    "            max_epochs=hparams['max_epochs'],\n",
    "            accelerator=\"gpu\",\n",
    "            # Use Distributed Data Parallel (activate on server0111)\n",
    "            strategy=\"ddp_notebook\" if is_interactive() else \"ddp\",\n",
    "            num_nodes=1,            # Number of nodes\n",
    "            devices=1,              # Number of GPUs to use\n",
    "            precision='16-mixed'    # Train with 16-bit precision (https://lightning.ai/docs/pytorch/stable/common/trainer.html#precision)\n",
    "        )\n",
    "\n",
    "        trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "        model.push_to_hub(\"crop-classification/messis\", commit_message=f\"Messis | W&B Run {wandb_logger.experiment.name} (https://wandb.ai/crop-classification/messis/runs/{wandb_logger.experiment.id})\")\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        def get_latest_commit_hash(repo_url):\n",
    "            process = subprocess.Popen([\"git\", \"ls-remote\", repo_url], stdout=subprocess.PIPE)\n",
    "            stdout, stderr = process.communicate()\n",
    "            if stderr:\n",
    "                print(f\"Error occurred fetching latest commit hash from ðŸ¤—: {stderr}\")\n",
    "                return \"unknwown\"\n",
    "            return re.split(r'\\t+', stdout.decode('ascii'))[0]\n",
    "\n",
    "        hf_repo_url = f\"{HF_MODEL_URL}.git\"\n",
    "        wandb_logger.experiment.config['huggingface_commit'] = f\"{HF_MODEL_URL}/commit/{get_latest_commit_hash(hf_repo_url)}\"\n",
    "        wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messis-E9xOSKpc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
