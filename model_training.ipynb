{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"model_training.ipynb\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import yaml\n",
    "import dvc.api\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from messis.messis import Messis, LogConfusionMatrix, LogMessisMetrics\n",
    "from messis.dataloader import GeospatialDataModule\n",
    "\n",
    "params = dvc.api.params_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a W&B logger\n",
    "wandb_logger = WandbLogger(entity='crop-classification', project='messis', log_model=False)\n",
    "\n",
    "with open(params['paths']['chips_stats'], 'r') as file:\n",
    "    chips_stats = yaml.safe_load(file)\n",
    "\n",
    "# Hyperparameters\n",
    "hparams = {\n",
    "    'img_size': 224,\n",
    "    'patch_size': 16,\n",
    "    'num_frames': 3,\n",
    "    'bands': [0, 1, 2, 3, 4, 5],\n",
    "    'debug': False,\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 4,\n",
    "    'accumulate_grad_batches': 1,\n",
    "    'max_epochs': 5,\n",
    "    # 'subsets': {\n",
    "    #     'train': 4,\n",
    "    #     'val': 2,\n",
    "    # },\n",
    "    'tiers': {\n",
    "        'tier1': {\n",
    "            'loss_weight': 1,\n",
    "            'num_classes': chips_stats['num_classes_tier1'],\n",
    "        },\n",
    "        'tier2': {\n",
    "            'loss_weight': 1,\n",
    "            'num_classes': chips_stats['num_classes_tier2'],\n",
    "        },\n",
    "        'tier3': {\n",
    "            'loss_weight': 1,\n",
    "            'num_classes': chips_stats['num_classes_tier3'],\n",
    "        },\n",
    "        'tier3_refined': {\n",
    "            'loss_weight': 1,\n",
    "            'num_classes': chips_stats['num_classes_tier3'],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# TODO add these to the params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Messis(hparams)\n",
    "\n",
    "data_module = GeospatialDataModule(\n",
    "    data_dir='./data/', \n",
    "    test_fold=0, \n",
    "    batch_size=hparams.get('batch_size', 4), \n",
    "    num_workers=2, \n",
    "    debug=False, \n",
    "    subsets=hparams.get('subsets', None)\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=3,          # Number of epochs to wait for improvement\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[\n",
    "        LogMessisMetrics  (hparams, params['paths']['dataset_info'], debug=False),\n",
    "        LogConfusionMatrix(hparams, params['paths']['dataset_info'], debug=False),\n",
    "        early_stopping\n",
    "    ],\n",
    "    accumulate_grad_batches=hparams['accumulate_grad_batches'],  # Gradient accumulation\n",
    "    max_epochs=hparams['max_epochs'],\n",
    "    accelerator=\"gpu\",\n",
    "    strategy=\"ddp\",         # Use Distributed Data Parallel\n",
    "    num_nodes=1,            # Number of nodes\n",
    "    devices=2,              # Number of GPUs to use\n",
    "    precision='16-mixed'    # Train with 16-bit precision (https://lightning.ai/docs/pytorch/stable/common/trainer.html#precision)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messis-E9xOSKpc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
