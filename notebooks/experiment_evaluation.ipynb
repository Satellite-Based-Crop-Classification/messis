{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import texttable as tt\n",
    "import latextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_GROUP = \"exp-1-dataset-split-strategy\"\n",
    "BASELINE_SETUP = \"random\"\n",
    "AVERAGE_EPOCHS = 0 # 5 or 0 | 0 for no averaging, must be odd\n",
    "HAS_WEIGHTED_ACCURACY = False\n",
    "FIRST_N_METRICS = 6 #6 # Only weighted_accuracy and macro_f1 for the results table in experiment results section\n",
    "EXCLUDED_SETUPS = [] # [0, 1] | list of setups to exclude, by their index in the list of setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 runs for experiment group 'exp-1-dataset-split-strategy'\n",
      "Run https://wandb.ai/crop-classification/messis/runs/tmmtb4ce - Missing 'name' in config, getting it from 'experiment_name' instead: random\n",
      "Run https://wandb.ai/crop-classification/messis/runs/04lknbug - Missing 'name' in config, getting it from 'experiment_name' instead: random\n",
      "Setup 'stratified-longer' - 1 runs\n",
      "Setup 'stratified-long' - 1 runs\n",
      "Setup 'sechidis' - 5 runs\n",
      "Setup 'random' - 5 runs\n",
      "Setup 'bands' - 5 runs\n",
      "Setup 'stratified' - 5 runs\n",
      "Run https://wandb.ai/crop-classification/messis/runs/islwn1g7 - Best epoch: 7434 - val_f1_tier3_majority: 0.194545179605484\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1wx9c8fy - Best epoch: 2064 - val_f1_tier3_majority: 0.14845073223114014\n",
      "Run https://wandb.ai/crop-classification/messis/runs/lfj8cwu4 - Best epoch: 1050 - val_f1_tier3_majority: 0.10101296752691269\n",
      "Run https://wandb.ai/crop-classification/messis/runs/hmm1uo25 - Best epoch: 1021 - val_f1_tier3_majority: 0.09414322674274445\n",
      "Run https://wandb.ai/crop-classification/messis/runs/a42lq9q5 - Best epoch: 1122 - val_f1_tier3_majority: 0.11358730494976044\n",
      "Run https://wandb.ai/crop-classification/messis/runs/kstftel1 - Best epoch: 1103 - val_f1_tier3_majority: 0.11487558484077454\n",
      "Run https://wandb.ai/crop-classification/messis/runs/eyy303wc - Best epoch: 1109 - val_f1_tier3_majority: 0.09648671746253967\n",
      "Run https://wandb.ai/crop-classification/messis/runs/tmmtb4ce - Best epoch: 1187 - val_f1_tier3_majority: 0.1257963627576828\n",
      "Run https://wandb.ai/crop-classification/messis/runs/04lknbug - Best epoch: 1498 - val_f1_tier3_majority: 0.12523344159126282\n",
      "Run https://wandb.ai/crop-classification/messis/runs/qj4o4ati - Best epoch: 1326 - val_f1_tier3_majority: 0.1224350854754448\n",
      "Run https://wandb.ai/crop-classification/messis/runs/2zgnr3fw - Best epoch: 1247 - val_f1_tier3_majority: 0.11528176069259644\n",
      "Run https://wandb.ai/crop-classification/messis/runs/mudkttvj - Best epoch: 1065 - val_f1_tier3_majority: 0.08383246511220932\n",
      "Run https://wandb.ai/crop-classification/messis/runs/fyumjoqi - Best epoch: 740 - val_f1_tier3_majority: 0.06623527407646179\n",
      "Run https://wandb.ai/crop-classification/messis/runs/4nu14ssi - Best epoch: 1392 - val_f1_tier3_majority: 0.12446334213018417\n",
      "Run https://wandb.ai/crop-classification/messis/runs/lzkvcm2x - Best epoch: 1520 - val_f1_tier3_majority: 0.1230330765247345\n",
      "Run https://wandb.ai/crop-classification/messis/runs/mc68cdlz - Best epoch: 899 - val_f1_tier3_majority: 0.09607546776533127\n",
      "Run https://wandb.ai/crop-classification/messis/runs/blfh8ee4 - Best epoch: 869 - val_f1_tier3_majority: 0.12688036262989044\n",
      "Run https://wandb.ai/crop-classification/messis/runs/av80hhcp - Best epoch: 1119 - val_f1_tier3_majority: 0.10187128931283951\n",
      "Run https://wandb.ai/crop-classification/messis/runs/lf9khgx7 - Best epoch: 1073 - val_f1_tier3_majority: 0.09486149251461029\n",
      "Run https://wandb.ai/crop-classification/messis/runs/8591uumk - Best epoch: 1056 - val_f1_tier3_majority: 0.09655706584453583\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f8oi85s8 - Best epoch: 1201 - val_f1_tier3_majority: 0.10256677120923996\n",
      "Run https://wandb.ai/crop-classification/messis/runs/vjyei1p5 - Best epoch: 816 - val_f1_tier3_majority: 0.10469336807727814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>num_runs</th>\n",
       "      <th>average_epochs</th>\n",
       "      <th>run_handles</th>\n",
       "      <th>best_steps</th>\n",
       "      <th>val_f1_tier1_majority_mean</th>\n",
       "      <th>val_f1_tier1_majority_std</th>\n",
       "      <th>val_f1_tier2_majority_mean</th>\n",
       "      <th>val_f1_tier2_majority_std</th>\n",
       "      <th>val_f1_tier3_majority_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>val_recall_tier2_majority_mean</th>\n",
       "      <th>val_recall_tier2_majority_std</th>\n",
       "      <th>val_recall_tier3_majority_mean</th>\n",
       "      <th>val_recall_tier3_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stratified-longer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[islwn1g7]</td>\n",
       "      <td>[7434]</td>\n",
       "      <td>0.390121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.725088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679943</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stratified-long</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1wx9c8fy]</td>\n",
       "      <td>[2064]</td>\n",
       "      <td>0.389849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sechidis</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[lfj8cwu4, hmm1uo25, a42lq9q5, kstftel1, eyy30...</td>\n",
       "      <td>[1050, 1021, 1122, 1103, 1109]</td>\n",
       "      <td>0.397259</td>\n",
       "      <td>0.046656</td>\n",
       "      <td>0.227932</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.104021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229077</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>0.111453</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.823467</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.652736</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.580093</td>\n",
       "      <td>0.011586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[tmmtb4ce, 04lknbug, qj4o4ati, 2zgnr3fw, mudkt...</td>\n",
       "      <td>[1187, 1498, 1326, 1247, 1065]</td>\n",
       "      <td>0.428437</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>0.234024</td>\n",
       "      <td>0.023781</td>\n",
       "      <td>0.114516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241598</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.123559</td>\n",
       "      <td>0.015195</td>\n",
       "      <td>0.842893</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>0.675422</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>0.604248</td>\n",
       "      <td>0.004763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bands</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[fyumjoqi, 4nu14ssi, lzkvcm2x, mc68cdlz, blfh8...</td>\n",
       "      <td>[740, 1392, 1520, 899, 869]</td>\n",
       "      <td>0.397116</td>\n",
       "      <td>0.071495</td>\n",
       "      <td>0.222217</td>\n",
       "      <td>0.034746</td>\n",
       "      <td>0.107338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230282</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>0.017932</td>\n",
       "      <td>0.786599</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.615557</td>\n",
       "      <td>0.056843</td>\n",
       "      <td>0.553128</td>\n",
       "      <td>0.057338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stratified</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[av80hhcp, lf9khgx7, 8591uumk, f8oi85s8, vjyei...</td>\n",
       "      <td>[1119, 1073, 1056, 1201, 816]</td>\n",
       "      <td>0.387703</td>\n",
       "      <td>0.040898</td>\n",
       "      <td>0.218297</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.100110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218198</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>0.103648</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.797149</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.628228</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.560959</td>\n",
       "      <td>0.015068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               setup  num_runs  average_epochs  \\\n",
       "0  stratified-longer         1               0   \n",
       "1    stratified-long         1               0   \n",
       "2           sechidis         5               0   \n",
       "3             random         5               0   \n",
       "4              bands         5               0   \n",
       "5         stratified         5               0   \n",
       "\n",
       "                                         run_handles  \\\n",
       "0                                         [islwn1g7]   \n",
       "1                                         [1wx9c8fy]   \n",
       "2  [lfj8cwu4, hmm1uo25, a42lq9q5, kstftel1, eyy30...   \n",
       "3  [tmmtb4ce, 04lknbug, qj4o4ati, 2zgnr3fw, mudkt...   \n",
       "4  [fyumjoqi, 4nu14ssi, lzkvcm2x, mc68cdlz, blfh8...   \n",
       "5  [av80hhcp, lf9khgx7, 8591uumk, f8oi85s8, vjyei...   \n",
       "\n",
       "                       best_steps  val_f1_tier1_majority_mean  \\\n",
       "0                          [7434]                    0.390121   \n",
       "1                          [2064]                    0.389849   \n",
       "2  [1050, 1021, 1122, 1103, 1109]                    0.397259   \n",
       "3  [1187, 1498, 1326, 1247, 1065]                    0.428437   \n",
       "4     [740, 1392, 1520, 899, 869]                    0.397116   \n",
       "5   [1119, 1073, 1056, 1201, 816]                    0.387703   \n",
       "\n",
       "   val_f1_tier1_majority_std  val_f1_tier2_majority_mean  \\\n",
       "0                   0.000000                    0.274251   \n",
       "1                   0.000000                    0.268020   \n",
       "2                   0.046656                    0.227932   \n",
       "3                   0.073525                    0.234024   \n",
       "4                   0.071495                    0.222217   \n",
       "5                   0.040898                    0.218297   \n",
       "\n",
       "   val_f1_tier2_majority_std  val_f1_tier3_majority_mean  ...  \\\n",
       "0                   0.000000                    0.194545  ...   \n",
       "1                   0.000000                    0.148451  ...   \n",
       "2                   0.017764                    0.104021  ...   \n",
       "3                   0.023781                    0.114516  ...   \n",
       "4                   0.034746                    0.107338  ...   \n",
       "5                   0.015290                    0.100110  ...   \n",
       "\n",
       "   val_recall_tier2_majority_mean  val_recall_tier2_majority_std  \\\n",
       "0                        0.260451                       0.000000   \n",
       "1                        0.250327                       0.000000   \n",
       "2                        0.229077                       0.018933   \n",
       "3                        0.241598                       0.024813   \n",
       "4                        0.230282                       0.025620   \n",
       "5                        0.218198                       0.011233   \n",
       "\n",
       "   val_recall_tier3_majority_mean  val_recall_tier3_majority_std  \\\n",
       "0                        0.185722                       0.000000   \n",
       "1                        0.149984                       0.000000   \n",
       "2                        0.111453                       0.010005   \n",
       "3                        0.123559                       0.015195   \n",
       "4                        0.116377                       0.017932   \n",
       "5                        0.103648                       0.003964   \n",
       "\n",
       "   val_cohen_kappa_tier1_majority_mean  val_cohen_kappa_tier1_majority_std  \\\n",
       "0                             0.868168                            0.000000   \n",
       "1                             0.847390                            0.000000   \n",
       "2                             0.823467                            0.030677   \n",
       "3                             0.842893                            0.011668   \n",
       "4                             0.786599                            0.019260   \n",
       "5                             0.797149                            0.035573   \n",
       "\n",
       "   val_cohen_kappa_tier2_majority_mean  val_cohen_kappa_tier2_majority_std  \\\n",
       "0                             0.725088                            0.000000   \n",
       "1                             0.709557                            0.000000   \n",
       "2                             0.652736                            0.013962   \n",
       "3                             0.675422                            0.012982   \n",
       "4                             0.615557                            0.056843   \n",
       "5                             0.628228                            0.020299   \n",
       "\n",
       "   val_cohen_kappa_tier3_majority_mean  val_cohen_kappa_tier3_majority_std  \n",
       "0                             0.679943                            0.000000  \n",
       "1                             0.656246                            0.000000  \n",
       "2                             0.580093                            0.011586  \n",
       "3                             0.604248                            0.004763  \n",
       "4                             0.553128                            0.057338  \n",
       "5                             0.560959                            0.015068  \n",
       "\n",
       "[6 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_epoch_metrics(run, metric_name, average_epochs=0):\n",
    "    history = pd.DataFrame(list(run.scan_history()))\n",
    "    \n",
    "    # Find the epoch with the best metric value\n",
    "    best_epoch = history[metric_name].idxmax()\n",
    "    best_metrics = history.loc[best_epoch]\n",
    "    if average_epochs > 0:\n",
    "        # Find indices of valid (non-NaN) values\n",
    "        valid_indices = history[metric_name].dropna().index\n",
    "        \n",
    "        # Locate the best epoch index in the valid indices\n",
    "        best_index_position = valid_indices.get_loc(best_epoch)\n",
    "        \n",
    "        # Get the indices of the average_epochs epochs to be averaged\n",
    "        idx_adjustment = (average_epochs - 1) // 2\n",
    "        start_index = max(0, best_index_position - idx_adjustment)\n",
    "        end_index = min(len(valid_indices), best_index_position + idx_adjustment + 1)\n",
    "        selected_indices = valid_indices[start_index:end_index]\n",
    "        \n",
    "        # Average the metrics over the selected epochs\n",
    "        averaged_metrics = history.loc[selected_indices].mean() # TOOD: Fix error\n",
    "        \n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} (averaged over {average_epochs}) - {metric_name}: {averaged_metrics[metric_name]}\")\n",
    "        return averaged_metrics, best_epoch\n",
    "    else:\n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} - {metric_name}: {best_metrics[metric_name]}\")\n",
    "        return best_metrics, best_epoch\n",
    "\n",
    "def gather_metrics_for_experiment_group(experiment_group, average_epochs=0, has_weighted_accuracy=True):\n",
    "    api = wandb.Api(timeout=60)\n",
    "\n",
    "    # Fetch runs matching the experiment group\n",
    "    runs = api.runs(\"crop-classification/messis\", filters={\"config.experiment_group\": experiment_group})\n",
    "    print(f\"Found {len(runs)} runs for experiment group '{experiment_group}'\")\n",
    "\n",
    "    # Organize the runs by setup name\n",
    "    setups = {}\n",
    "    for run in runs:\n",
    "        if run.state != 'finished':\n",
    "            print(f\"Run {run.url} - Skipping (not finished, state: {run.state})\")\n",
    "            continue\n",
    "        if 'name' not in run.config:\n",
    "            if 'experiment_name' in run.config:\n",
    "                setup_name = run.config['experiment_name'].split('-')[-1]\n",
    "                print(f\"Run {run.url} - Missing 'name' in config, getting it from 'experiment_name' instead: {setup_name}\")\n",
    "            else:\n",
    "                print(f\"Run {run.url} - Missing 'name' in config, skipping\")\n",
    "                continue\n",
    "        else:\n",
    "            setup_name = run.config['name']\n",
    "        if setup_name not in setups:\n",
    "            setups[setup_name] = {\n",
    "                'runs': [],\n",
    "                'metrics': {metric: [] for metric in [\n",
    "                    'val_f1_tier1_majority',\n",
    "                    'val_f1_tier2_majority',\n",
    "                    'val_f1_tier3_majority',\n",
    "                    'val_weighted_accuracy_tier1_majority' if has_weighted_accuracy else 'val_accuracy_tier1_majority',\n",
    "                    'val_weighted_accuracy_tier2_majority' if has_weighted_accuracy else 'val_accuracy_tier2_majority',\n",
    "                    'val_weighted_accuracy_tier3_majority' if has_weighted_accuracy else 'val_accuracy_tier3_majority',\n",
    "                    'val_precision_tier1_majority',\n",
    "                    'val_precision_tier2_majority',\n",
    "                    'val_precision_tier3_majority',\n",
    "                    'val_recall_tier1_majority',\n",
    "                    'val_recall_tier2_majority',\n",
    "                    'val_recall_tier3_majority',\n",
    "                    'val_cohen_kappa_tier1_majority',\n",
    "                    'val_cohen_kappa_tier2_majority',\n",
    "                    'val_cohen_kappa_tier3_majority',\n",
    "                ]},\n",
    "                'best_steps': []\n",
    "            }\n",
    "        setups[setup_name]['runs'].append(run)\n",
    "\n",
    "    # Print setup names with number of runs\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        print(f\"Setup '{setup_name}' - {len(setup_data['runs'])} runs\")\n",
    "\n",
    "    # Gather metrics for each setup\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        for run in setup_data['runs']:\n",
    "            best_metrics, best_epoch = get_best_epoch_metrics(run, 'val_f1_tier3_majority', average_epochs)\n",
    "            setup_data['best_steps'].append(best_epoch)\n",
    "            for metric in setup_data['metrics']:\n",
    "                setup_data['metrics'][metric].append(best_metrics[metric])\n",
    "    \n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        metrics_summary = {\n",
    "            'setup': setup_name,\n",
    "            'num_runs': len(setup_data['runs']),\n",
    "            'average_epochs': average_epochs,\n",
    "            'run_handles': [run.id for run in setup_data['runs']],\n",
    "            'best_steps': setup_data['best_steps'],\n",
    "        }\n",
    "        for metric, values in setup_data['metrics'].items():\n",
    "            metrics_summary[f'{metric}_mean'] = np.mean(values)\n",
    "            metrics_summary[f'{metric}_std'] = np.std(values)\n",
    "        data.append(metrics_summary)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(data)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Run the function for a given experiment group\n",
    "metrics_df = gather_metrics_for_experiment_group(EXPERIMENT_GROUP, average_epochs=AVERAGE_EPOCHS, has_weighted_accuracy=HAS_WEIGHTED_ACCURACY)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\", index=False)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\t\\begin{center}\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{lcccccc}\n",
      "\t\t\t\\toprule\n",
      "\t\t\tMetric & $\\dagger$ random (5-fold) & bands (5-fold) & sechidis (5-fold) & stratified (5-fold) & stratified-long (1-fold) & stratified-longer (1-fold) \\\\\n",
      "\t\t\t\\midrule\n",
      "\t\t\tF1 $T_1$ & \\textbf{42.8\\% ± 7.4\\%} & 39.7\\% ± 7.1\\% & \\underline{39.7\\% ± 4.7\\%} & 38.8\\% ± 4.1\\% & 39.0\\% ± 0.0\\% & 39.0\\% ± 0.0\\% \\\\\n",
      "\t\t\tF1 $T_2$ & 23.4\\% ± 2.4\\% & 22.2\\% ± 3.5\\% & 22.8\\% ± 1.8\\% & 21.8\\% ± 1.5\\% & \\underline{26.8\\% ± 0.0\\%} & \\textbf{27.4\\% ± 0.0\\%} \\\\\n",
      "\t\t\tF1 $T_3$ & 11.5\\% ± 1.6\\% & 10.7\\% ± 2.3\\% & 10.4\\% ± 0.9\\% & 10.0\\% ± 0.4\\% & \\underline{14.8\\% ± 0.0\\%} & \\textbf{19.5\\% ± 0.0\\%} \\\\\n",
      "\t\t\tAcc. $T_1$ & \\textbf{43.2\\% ± 7.7\\%} & \\underline{40.1\\% ± 7.1\\%} & 38.8\\% ± 4.2\\% & 38.3\\% ± 3.4\\% & 36.3\\% ± 0.0\\% & 36.5\\% ± 0.0\\% \\\\\n",
      "\t\t\tAcc. $T_2$ & 24.2\\% ± 2.5\\% & 23.0\\% ± 2.6\\% & 22.9\\% ± 1.9\\% & 21.8\\% ± 1.1\\% & \\underline{25.0\\% ± 0.0\\%} & \\textbf{26.0\\% ± 0.0\\%} \\\\\n",
      "\t\t\tAcc. $T_3$ & 12.4\\% ± 1.5\\% & 11.6\\% ± 1.8\\% & 11.1\\% ± 1.0\\% & 10.4\\% ± 0.4\\% & \\underline{15.0\\% ± 0.0\\%} & \\textbf{18.6\\% ± 0.0\\%} \\\\\n",
      "\t\t\t\\bottomrule\n",
      "\t\t\\end{tabular}\n",
      "\t}\\end{center}\n",
      "\t\\caption{Results for experiment exp-1-dataset-split-strategy. All metrics calculated on field majority during validation phase, with mean and std reported. Best scores bold, second best underlined, $\\dagger$ is baseline.}\n",
      "\t\\label{tab:metrics_comparison_exp-1-dataset-split-strategy}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Mapping for short metric names\n",
    "metric_name_mapping = {\n",
    "    'val_f1_tier1_majority': 'F1 $T_1$',\n",
    "    'val_f1_tier2_majority': 'F1 $T_2$',\n",
    "    'val_f1_tier3_majority': 'F1 $T_3$',\n",
    "}\n",
    "\n",
    "if HAS_WEIGHTED_ACCURACY:\n",
    "    metric_name_mapping['val_weighted_accuracy_tier1_majority'] = 'W. Acc. $T_1$'\n",
    "    metric_name_mapping['val_weighted_accuracy_tier2_majority'] = 'W. Acc. $T_2$'\n",
    "    metric_name_mapping['val_weighted_accuracy_tier3_majority'] = 'W. Acc. $T_3$'\n",
    "else:\n",
    "    metric_name_mapping['val_accuracy_tier1_majority'] = 'Acc. $T_1$'\n",
    "    metric_name_mapping['val_accuracy_tier2_majority'] = 'Acc. $T_2$'\n",
    "    metric_name_mapping['val_accuracy_tier3_majority'] = 'Acc. $T_3$'\n",
    "\n",
    "metric_name_mapping = { # Adding further metrics down here, to make sure we keep the most relevant metrics at the top\n",
    "    **metric_name_mapping,\n",
    "    'val_precision_tier1_majority': 'Precision $T_1$',\n",
    "    'val_precision_tier2_majority': 'Precision $T_2$',\n",
    "    'val_precision_tier3_majority': 'Precision $T_3$',\n",
    "    'val_recall_tier1_majority': 'Recall $T_1$',\n",
    "    'val_recall_tier2_majority': 'Recall $T_2$',\n",
    "    'val_recall_tier3_majority': 'Recall $T_3$',\n",
    "    'val_cohen_kappa_tier1_majority': 'Kappa $T_1$',\n",
    "    'val_cohen_kappa_tier2_majority': 'Kappa $T_2$',\n",
    "    'val_cohen_kappa_tier3_majority': 'Kappa $T_3$',\n",
    "}\n",
    "\n",
    "# Function to create a LaTeX table with bold best scores and underlined second-best scores\n",
    "def create_latex_table(df, baseline_setup, first_n_metrics=None):\n",
    "    metrics = list(metric_name_mapping.keys())\n",
    "    if first_n_metrics:\n",
    "        metrics = metrics[:first_n_metrics]\n",
    "    \n",
    "    # Determine the best and second-best scores for each metric\n",
    "    best_scores = {metric: df[f'{metric}_mean'].max() for metric in metrics}\n",
    "    second_best_scores = {\n",
    "        metric: sorted(df[f'{metric}_mean'].unique(), reverse=True)[1] if len(df[f'{metric}_mean'].unique()) > 1 else None\n",
    "        for metric in metrics\n",
    "    }\n",
    "\n",
    "    # Reorder the dataframe to have the baseline setup first\n",
    "    df = df.set_index('setup')\n",
    "    if baseline_setup in df.index:\n",
    "        df = df.loc[[baseline_setup] + [idx for idx in df.index if idx != baseline_setup]].reset_index()\n",
    "    else:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    # Initialize the Texttable object\n",
    "    table = tt.Texttable()\n",
    "    \n",
    "    # Define the header\n",
    "    headers = ['Metric'] + [f\"{'$\\\\dagger$ ' if row['setup'] == baseline_setup else ''}{setup} ({row['num_runs']}-fold)\" \n",
    "                            for idx, row in df.iterrows() for setup in [row['setup']]]\n",
    "    table.header(headers)\n",
    "    \n",
    "    # Set alignment for columns\n",
    "    cols_align = [\"c\"] * len(headers)\n",
    "    cols_align[0] = \"l\"\n",
    "    table.set_cols_align(cols_align)\n",
    "    \n",
    "    # Populate the table with data\n",
    "    for metric in metrics:\n",
    "        row_data = [metric_name_mapping[metric]]\n",
    "        for idx, row in df.iterrows():\n",
    "            mean = row[f'{metric}_mean'] * 100\n",
    "            std = row[f'{metric}_std'] * 100\n",
    "            value = f'{mean:.1f}\\\\% ± {std:.1f}\\\\%'\n",
    "            if mean == best_scores[metric] * 100:\n",
    "                value = f'\\\\textbf{{{value}}}'\n",
    "            elif second_best_scores[metric] and mean == second_best_scores[metric] * 100:\n",
    "                value = f'\\\\underline{{{value}}}'\n",
    "            row_data.append(value)\n",
    "        table.add_row(row_data)\n",
    "    \n",
    "    # Generate the LaTeX table\n",
    "    average_epochs_used = df['average_epochs'].iloc[0] \n",
    "    caption_averaged =  \"\" if average_epochs_used == 0 else f\" averaged over {average_epochs_used} epochs\"\n",
    "    latex_table = latextable.draw_latex(\n",
    "        table, \n",
    "        caption=f\"Results for experiment {EXPERIMENT_GROUP}. All metrics calculated on field majority during validation phase{caption_averaged}, with mean and std reported. Best scores bold, second best underlined, $\\\\dagger$ is baseline.\", \n",
    "        label=f\"tab:metrics_comparison_{EXPERIMENT_GROUP}\", \n",
    "        use_booktabs=True,\n",
    "        position=\"h\"\n",
    "    )\n",
    "\n",
    "    # Add \\resizebox to the LaTeX table\n",
    "    latex_table = latex_table.replace('\\\\begin{center}', '\\\\begin{center}\\\\resizebox{\\\\textwidth}{!}{')\n",
    "    latex_table = latex_table.replace('\\\\end{center}', '}\\\\end{center}')\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Generate the LaTeX table\n",
    "df = pd.read_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\")\n",
    "df = df.sort_values(by='setup')\n",
    "\n",
    "# Optional: Drop rows to exclude some setups\n",
    "df = df.drop(EXCLUDED_SETUPS)\n",
    "\n",
    "latex_table = create_latex_table(df, baseline_setup=BASELINE_SETUP, first_n_metrics=FIRST_N_METRICS)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messis-bV8Bs8aq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
