{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import texttable as tt\n",
    "import latextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_GROUP = \"exp-7-label-hierarchy\"\n",
    "BASELINE_SETUP = \"zueri_crop\"\n",
    "AVERAGE_EPOCHS = 0 # 5 or 0 | 0 for no averaging, must be odd\n",
    "HAS_WEIGHTED_ACCURACY = True\n",
    "FIRST_N_METRICS = 6 #6 # Only weighted_accuracy and macro_f1 for the results table in experiment results section\n",
    "EXCLUDED_SETUPS = [] # [0, 1] | list of setups to exclude, by their index in the list of setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 runs for experiment group 'exp-7-label-hierarchy'\n",
      "Setup 'zueri_crop' - 5 runs\n",
      "Setup 'seasonality-reduced' - 5 runs\n",
      "Setup 'seasonality' - 5 runs\n",
      "Run https://wandb.ai/crop-classification/messis/runs/pwqkbwq6 - Best epoch: 1176 - val_f1_tier3_majority: 0.16037622094154358\n",
      "Run https://wandb.ai/crop-classification/messis/runs/rd7lv507 - Best epoch: 2368 - val_f1_tier3_majority: 0.19019684195518494\n",
      "Run https://wandb.ai/crop-classification/messis/runs/q3nmx7p1 - Best epoch: 2442 - val_f1_tier3_majority: 0.19210368394851685\n",
      "Run https://wandb.ai/crop-classification/messis/runs/6s2tj86v - Best epoch: 1697 - val_f1_tier3_majority: 0.18803294003009796\n",
      "Run https://wandb.ai/crop-classification/messis/runs/0nk545h7 - Best epoch: 1883 - val_f1_tier3_majority: 0.195332869887352\n",
      "Run https://wandb.ai/crop-classification/messis/runs/143c6j7s - Best epoch: 2649 - val_f1_tier2_majority: 0.37494200468063354\n",
      "Run https://wandb.ai/crop-classification/messis/runs/143c6j7s - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/143c6j7s - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/143c6j7s - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/143c6j7s - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/143c6j7s - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=60 sec). Create a new API with an integer timeout larger than 60, e.g., `api = wandb.Api(timeout=70)` to increase the graphql timeout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run https://wandb.ai/crop-classification/messis/runs/7nt6gyrj - Best epoch: 2565 - val_f1_tier2_majority: 0.3646811842918396\n",
      "Run https://wandb.ai/crop-classification/messis/runs/7nt6gyrj - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/7nt6gyrj - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/7nt6gyrj - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/7nt6gyrj - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/7nt6gyrj - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/uwodwvw7 - Best epoch: 2396 - val_f1_tier2_majority: 0.37607842683792114\n",
      "Run https://wandb.ai/crop-classification/messis/runs/uwodwvw7 - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/uwodwvw7 - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/uwodwvw7 - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/uwodwvw7 - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/uwodwvw7 - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/sdyex3kh - Best epoch: 2776 - val_f1_tier2_majority: 0.3679090738296509\n",
      "Run https://wandb.ai/crop-classification/messis/runs/sdyex3kh - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/sdyex3kh - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/sdyex3kh - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/sdyex3kh - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/sdyex3kh - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1lwxjir1 - Best epoch: 2565 - val_f1_tier2_majority: 0.3636426031589508\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1lwxjir1 - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1lwxjir1 - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1lwxjir1 - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1lwxjir1 - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1lwxjir1 - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/m1t1f3vk - Best epoch: 1830 - val_f1_tier2_majority: 0.26061466336250305\n",
      "Run https://wandb.ai/crop-classification/messis/runs/m1t1f3vk - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/m1t1f3vk - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/m1t1f3vk - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/m1t1f3vk - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/m1t1f3vk - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f7urajrh - Best epoch: 1977 - val_f1_tier2_majority: 0.2332957237958908\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f7urajrh - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f7urajrh - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f7urajrh - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f7urajrh - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f7urajrh - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=60 sec). Create a new API with an integer timeout larger than 60, e.g., `api = wandb.Api(timeout=70)` to increase the graphql timeout.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run https://wandb.ai/crop-classification/messis/runs/pt531h16 - Best epoch: 1626 - val_f1_tier2_majority: 0.24047327041625977\n",
      "Run https://wandb.ai/crop-classification/messis/runs/pt531h16 - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/pt531h16 - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/pt531h16 - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/pt531h16 - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/pt531h16 - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/prm2vmqr - Best epoch: 1596 - val_f1_tier2_majority: 0.23555506765842438\n",
      "Run https://wandb.ai/crop-classification/messis/runs/prm2vmqr - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/prm2vmqr - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/prm2vmqr - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/prm2vmqr - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/prm2vmqr - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/k3otzmsb - Best epoch: 1713 - val_f1_tier2_majority: 0.2161237597465515\n",
      "Run https://wandb.ai/crop-classification/messis/runs/k3otzmsb - Skipping metric 'val_f1_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/k3otzmsb - Skipping metric 'val_weighted_accuracy_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/k3otzmsb - Skipping metric 'val_precision_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/k3otzmsb - Skipping metric 'val_recall_tier3_majority' (not present in run)\n",
      "Run https://wandb.ai/crop-classification/messis/runs/k3otzmsb - Skipping metric 'val_cohen_kappa_tier3_majority' (not present in run)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvokeller/Library/Caches/pypoetry/virtualenvs/messis-bV8Bs8aq-py3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/yvokeller/Library/Caches/pypoetry/virtualenvs/messis-bV8Bs8aq-py3.12/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/yvokeller/Library/Caches/pypoetry/virtualenvs/messis-bV8Bs8aq-py3.12/lib/python3.12/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/yvokeller/Library/Caches/pypoetry/virtualenvs/messis-bV8Bs8aq-py3.12/lib/python3.12/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/yvokeller/Library/Caches/pypoetry/virtualenvs/messis-bV8Bs8aq-py3.12/lib/python3.12/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>num_runs</th>\n",
       "      <th>average_epochs</th>\n",
       "      <th>run_handles</th>\n",
       "      <th>best_steps</th>\n",
       "      <th>val_f1_tier1_majority_mean</th>\n",
       "      <th>val_f1_tier1_majority_std</th>\n",
       "      <th>val_f1_tier2_majority_mean</th>\n",
       "      <th>val_f1_tier2_majority_std</th>\n",
       "      <th>val_f1_tier3_majority_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>val_recall_tier2_majority_mean</th>\n",
       "      <th>val_recall_tier2_majority_std</th>\n",
       "      <th>val_recall_tier3_majority_mean</th>\n",
       "      <th>val_recall_tier3_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zueri_crop</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[pwqkbwq6, rd7lv507, q3nmx7p1, 6s2tj86v, 0nk54...</td>\n",
       "      <td>[1176, 2368, 2442, 1697, 1883]</td>\n",
       "      <td>0.470046</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>0.305209</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.185209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302757</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.180362</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>0.858347</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.720703</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.665835</td>\n",
       "      <td>0.012636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasonality-reduced</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[143c6j7s, 7nt6gyrj, uwodwvw7, sdyex3kh, 1lwxj...</td>\n",
       "      <td>[2649, 2565, 2396, 2776, 2565]</td>\n",
       "      <td>0.826030</td>\n",
       "      <td>0.113863</td>\n",
       "      <td>0.369451</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348367</td>\n",
       "      <td>0.009517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888578</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.787664</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seasonality</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[m1t1f3vk, f7urajrh, pt531h16, prm2vmqr, k3otz...</td>\n",
       "      <td>[1830, 1977, 1626, 1596, 1713]</td>\n",
       "      <td>0.824360</td>\n",
       "      <td>0.114030</td>\n",
       "      <td>0.237212</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227295</td>\n",
       "      <td>0.016365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.886850</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.776550</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 setup  num_runs  average_epochs  \\\n",
       "0           zueri_crop         5               0   \n",
       "1  seasonality-reduced         5               0   \n",
       "2          seasonality         5               0   \n",
       "\n",
       "                                         run_handles  \\\n",
       "0  [pwqkbwq6, rd7lv507, q3nmx7p1, 6s2tj86v, 0nk54...   \n",
       "1  [143c6j7s, 7nt6gyrj, uwodwvw7, sdyex3kh, 1lwxj...   \n",
       "2  [m1t1f3vk, f7urajrh, pt531h16, prm2vmqr, k3otz...   \n",
       "\n",
       "                       best_steps  val_f1_tier1_majority_mean  \\\n",
       "0  [1176, 2368, 2442, 1697, 1883]                    0.470046   \n",
       "1  [2649, 2565, 2396, 2776, 2565]                    0.826030   \n",
       "2  [1830, 1977, 1626, 1596, 1713]                    0.824360   \n",
       "\n",
       "   val_f1_tier1_majority_std  val_f1_tier2_majority_mean  \\\n",
       "0                   0.074460                    0.305209   \n",
       "1                   0.113863                    0.369451   \n",
       "2                   0.114030                    0.237212   \n",
       "\n",
       "   val_f1_tier2_majority_std  val_f1_tier3_majority_mean  ...  \\\n",
       "0                   0.016114                    0.185209  ...   \n",
       "1                   0.005156                         NaN  ...   \n",
       "2                   0.014291                         NaN  ...   \n",
       "\n",
       "   val_recall_tier2_majority_mean  val_recall_tier2_majority_std  \\\n",
       "0                        0.302757                       0.020736   \n",
       "1                        0.348367                       0.009517   \n",
       "2                        0.227295                       0.016365   \n",
       "\n",
       "   val_recall_tier3_majority_mean  val_recall_tier3_majority_std  \\\n",
       "0                        0.180362                       0.010957   \n",
       "1                             NaN                            NaN   \n",
       "2                             NaN                            NaN   \n",
       "\n",
       "   val_cohen_kappa_tier1_majority_mean  val_cohen_kappa_tier1_majority_std  \\\n",
       "0                             0.858347                            0.006692   \n",
       "1                             0.888578                            0.006405   \n",
       "2                             0.886850                            0.008232   \n",
       "\n",
       "   val_cohen_kappa_tier2_majority_mean  val_cohen_kappa_tier2_majority_std  \\\n",
       "0                             0.720703                            0.019470   \n",
       "1                             0.787664                            0.007515   \n",
       "2                             0.776550                            0.009927   \n",
       "\n",
       "   val_cohen_kappa_tier3_majority_mean  val_cohen_kappa_tier3_majority_std  \n",
       "0                             0.665835                            0.012636  \n",
       "1                                  NaN                                 NaN  \n",
       "2                                  NaN                                 NaN  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_epoch_metrics(run, metric_name, average_epochs=0):\n",
    "    history = pd.DataFrame(list(run.scan_history()))\n",
    "    \n",
    "    # Find the epoch with the best metric value\n",
    "    best_epoch = history[metric_name].idxmax()\n",
    "    best_metrics = history.loc[best_epoch]\n",
    "    if average_epochs > 0:\n",
    "        # Find indices of valid (non-NaN) values\n",
    "        valid_indices = history[metric_name].dropna().index\n",
    "        \n",
    "        # Locate the best epoch index in the valid indices\n",
    "        best_index_position = valid_indices.get_loc(best_epoch)\n",
    "        \n",
    "        # Get the indices of the average_epochs epochs to be averaged\n",
    "        idx_adjustment = (average_epochs - 1) // 2\n",
    "        start_index = max(0, best_index_position - idx_adjustment)\n",
    "        end_index = min(len(valid_indices), best_index_position + idx_adjustment + 1)\n",
    "        selected_indices = valid_indices[start_index:end_index]\n",
    "        \n",
    "        # Convert the selected indices to numeric, forcing errors to NaN - Use when averaging over epchs\n",
    "        # converted_history = history.loc[selected_indices].apply(pd.to_numeric, errors='coerce')\n",
    "        # converted_history.mean()\n",
    "\n",
    "        # Average the metrics over the selected epochs\n",
    "        averaged_metrics = history.loc[selected_indices].mean()\n",
    "        \n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} (averaged over {average_epochs}) - {metric_name}: {averaged_metrics[metric_name]}\")\n",
    "        return averaged_metrics, best_epoch\n",
    "    else:\n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} - {metric_name}: {best_metrics[metric_name]}\")\n",
    "        return best_metrics, best_epoch\n",
    "\n",
    "def gather_metrics_for_experiment_group(experiment_group, average_epochs=0, has_weighted_accuracy=True):\n",
    "    api = wandb.Api(timeout=60)\n",
    "\n",
    "    # Fetch runs matching the experiment group\n",
    "    runs = api.runs(\"crop-classification/messis\", filters={\"config.experiment_group\": experiment_group})\n",
    "    print(f\"Found {len(runs)} runs for experiment group '{experiment_group}'\")\n",
    "\n",
    "    # Organize the runs by setup name\n",
    "    setups = {}\n",
    "    for run in runs:\n",
    "        if run.state != 'finished':\n",
    "            print(f\"Run {run.url} - Skipping (not finished, state: {run.state})\")\n",
    "            continue\n",
    "        if 'name' not in run.config:\n",
    "            if 'experiment_name' in run.config:\n",
    "                setup_name = run.config['experiment_name'].split('-')[-1]\n",
    "                print(f\"Run {run.url} - Missing 'name' in config, getting it from 'experiment_name' instead: {setup_name}\")\n",
    "            else:\n",
    "                print(f\"Run {run.url} - Missing 'name' in config, skipping\")\n",
    "                continue\n",
    "        else:\n",
    "            setup_name = run.config['name']\n",
    "        if setup_name not in setups:\n",
    "            setups[setup_name] = {\n",
    "                'runs': [],\n",
    "                'metrics': {metric: [] for metric in [\n",
    "                    'val_f1_tier1_majority',\n",
    "                    'val_f1_tier2_majority',\n",
    "                    'val_f1_tier3_majority',\n",
    "                    'val_weighted_accuracy_tier1_majority' if has_weighted_accuracy else 'val_accuracy_tier1_majority',\n",
    "                    'val_weighted_accuracy_tier2_majority' if has_weighted_accuracy else 'val_accuracy_tier2_majority',\n",
    "                    'val_weighted_accuracy_tier3_majority' if has_weighted_accuracy else 'val_accuracy_tier3_majority',\n",
    "                    'val_precision_tier1_majority',\n",
    "                    'val_precision_tier2_majority',\n",
    "                    'val_precision_tier3_majority',\n",
    "                    'val_recall_tier1_majority',\n",
    "                    'val_recall_tier2_majority',\n",
    "                    'val_recall_tier3_majority',\n",
    "                    'val_cohen_kappa_tier1_majority',\n",
    "                    'val_cohen_kappa_tier2_majority',\n",
    "                    'val_cohen_kappa_tier3_majority',\n",
    "                ]},\n",
    "                'best_steps': []\n",
    "            }\n",
    "        setups[setup_name]['runs'].append(run)\n",
    "\n",
    "    # Print setup names with number of runs\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        print(f\"Setup '{setup_name}' - {len(setup_data['runs'])} runs\")\n",
    "\n",
    "    # Gather metrics for each setup\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        for run in setup_data['runs']:\n",
    "            best_metrics, best_epoch = get_best_epoch_metrics(run, 'val_f1_tier3_majority' if (setup_name != 'seasonality' and setup_name != 'seasonality-reduced') else 'val_f1_tier2_majority', average_epochs)\n",
    "            setup_data['best_steps'].append(best_epoch)\n",
    "            for metric in setup_data['metrics']:\n",
    "                # Skip metrics that are not present in the best_metrics\n",
    "                if metric not in best_metrics:\n",
    "                    print(f\"Run {run.url} - Skipping metric '{metric}' (not present in run)\")\n",
    "                    continue\n",
    "                setup_data['metrics'][metric].append(best_metrics[metric])\n",
    "    \n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        metrics_summary = {\n",
    "            'setup': setup_name,\n",
    "            'num_runs': len(setup_data['runs']),\n",
    "            'average_epochs': average_epochs,\n",
    "            'run_handles': [run.id for run in setup_data['runs']],\n",
    "            'best_steps': setup_data['best_steps'],\n",
    "        }\n",
    "        for metric, values in setup_data['metrics'].items():\n",
    "            metrics_summary[f'{metric}_mean'] = np.mean(values)\n",
    "            metrics_summary[f'{metric}_std'] = np.std(values)\n",
    "        data.append(metrics_summary)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(data)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Run the function for a given experiment group\n",
    "metrics_df = gather_metrics_for_experiment_group(EXPERIMENT_GROUP, average_epochs=AVERAGE_EPOCHS, has_weighted_accuracy=HAS_WEIGHTED_ACCURACY)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\", index=False)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\t\\begin{center}\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{lccc}\n",
      "\t\t\t\\toprule\n",
      "\t\t\tMetric & $\\dagger$ zueri\\_crop (5-fold) & seasonality (5-fold) & seasonality-reduced (5-fold) \\\\\n",
      "\t\t\t\\midrule\n",
      "\t\t\tF1 $T_1$ & 47.0\\% ± 7.4\\% & \\underline{82.4\\% ± 11.4\\%} & \\textbf{82.6\\% ± 11.4\\%} \\\\\n",
      "\t\t\tF1 $T_2$ & \\underline{30.5\\% ± 1.6\\%} & 23.7\\% ± 1.4\\% & \\textbf{36.9\\% ± 0.5\\%} \\\\\n",
      "\t\t\tF1 $T_3$ & \\textbf{18.5\\% ± 1.3\\%} & nan\\% ± nan\\% & nan\\% ± nan\\% \\\\\n",
      "\t\t\tW. Acc. $T_1$ & 92.8\\% ± 0.3\\% & \\underline{93.5\\% ± 0.5\\%} & \\textbf{93.6\\% ± 0.4\\%} \\\\\n",
      "\t\t\tW. Acc. $T_2$ & 80.6\\% ± 1.8\\% & \\underline{85.4\\% ± 0.7\\%} & \\textbf{86.2\\% ± 0.5\\%} \\\\\n",
      "\t\t\tW. Acc. $T_3$ & \\textbf{76.0\\% ± 1.4\\%} & nan\\% ± nan\\% & nan\\% ± nan\\% \\\\\n",
      "\t\t\t\\bottomrule\n",
      "\t\t\\end{tabular}\n",
      "\t}\\end{center}\n",
      "\t\\caption{Results for experiment exp-7-label-hierarchy. All metrics calculated on field majority during validation phase, with mean and std reported. Best scores bold, second best underlined, $\\dagger$ is baseline.}\n",
      "\t\\label{tab:metrics_comparison_exp-7-label-hierarchy}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Mapping for short metric names\n",
    "metric_name_mapping = {\n",
    "    'val_f1_tier1_majority': 'F1 $T_1$',\n",
    "    'val_f1_tier2_majority': 'F1 $T_2$',\n",
    "    'val_f1_tier3_majority': 'F1 $T_3$',\n",
    "}\n",
    "\n",
    "if HAS_WEIGHTED_ACCURACY:\n",
    "    metric_name_mapping['val_weighted_accuracy_tier1_majority'] = 'W. Acc. $T_1$'\n",
    "    metric_name_mapping['val_weighted_accuracy_tier2_majority'] = 'W. Acc. $T_2$'\n",
    "    metric_name_mapping['val_weighted_accuracy_tier3_majority'] = 'W. Acc. $T_3$'\n",
    "else:\n",
    "    metric_name_mapping['val_accuracy_tier1_majority'] = 'Acc. $T_1$'\n",
    "    metric_name_mapping['val_accuracy_tier2_majority'] = 'Acc. $T_2$'\n",
    "    metric_name_mapping['val_accuracy_tier3_majority'] = 'Acc. $T_3$'\n",
    "\n",
    "metric_name_mapping = { # Adding further metrics down here, to make sure we keep the most relevant metrics at the top\n",
    "    **metric_name_mapping,\n",
    "    'val_precision_tier1_majority': 'Precision $T_1$',\n",
    "    'val_precision_tier2_majority': 'Precision $T_2$',\n",
    "    'val_precision_tier3_majority': 'Precision $T_3$',\n",
    "    'val_recall_tier1_majority': 'Recall $T_1$',\n",
    "    'val_recall_tier2_majority': 'Recall $T_2$',\n",
    "    'val_recall_tier3_majority': 'Recall $T_3$',\n",
    "    'val_cohen_kappa_tier1_majority': 'Kappa $T_1$',\n",
    "    'val_cohen_kappa_tier2_majority': 'Kappa $T_2$',\n",
    "    'val_cohen_kappa_tier3_majority': 'Kappa $T_3$',\n",
    "}\n",
    "\n",
    "# Function to create a LaTeX table with bold best scores and underlined second-best scores\n",
    "def create_latex_table(df, baseline_setup, first_n_metrics=None):\n",
    "    metrics = list(metric_name_mapping.keys())\n",
    "    if first_n_metrics:\n",
    "        metrics = metrics[:first_n_metrics]\n",
    "    \n",
    "    # Determine the best and second-best scores for each metric\n",
    "    best_scores = {metric: df[f'{metric}_mean'].max() for metric in metrics}\n",
    "    second_best_scores = {\n",
    "        metric: sorted(df[f'{metric}_mean'].unique(), reverse=True)[1] if len(df[f'{metric}_mean'].unique()) > 1 else None\n",
    "        for metric in metrics\n",
    "    }\n",
    "\n",
    "    # Reorder the dataframe to have the baseline setup first\n",
    "    df = df.set_index('setup')\n",
    "    if baseline_setup in df.index:\n",
    "        df = df.loc[[baseline_setup] + [idx for idx in df.index if idx != baseline_setup]].reset_index()\n",
    "    else:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    # Initialize the Texttable object\n",
    "    table = tt.Texttable()\n",
    "    \n",
    "    # Define the header\n",
    "    headers = ['Metric'] + [f\"{'$\\\\dagger$ ' if row['setup'] == baseline_setup else ''}{str(setup).replace('_', '\\\\_')} ({row['num_runs']}-fold)\" \n",
    "                            for idx, row in df.iterrows() for setup in [row['setup']]]\n",
    "    table.header(headers)\n",
    "    \n",
    "    # Set alignment for columns\n",
    "    cols_align = [\"c\"] * len(headers)\n",
    "    cols_align[0] = \"l\"\n",
    "    table.set_cols_align(cols_align)\n",
    "    \n",
    "    # Populate the table with data\n",
    "    for metric in metrics:\n",
    "        row_data = [metric_name_mapping[metric]]\n",
    "        for idx, row in df.iterrows():\n",
    "            mean = row[f'{metric}_mean'] * 100\n",
    "            std = row[f'{metric}_std'] * 100\n",
    "            value = f'{mean:.1f}\\\\% ± {std:.1f}\\\\%'\n",
    "            if mean == best_scores[metric] * 100:\n",
    "                value = f'\\\\textbf{{{value}}}'\n",
    "            elif second_best_scores[metric] and mean == second_best_scores[metric] * 100:\n",
    "                value = f'\\\\underline{{{value}}}'\n",
    "            row_data.append(value)\n",
    "        table.add_row(row_data)\n",
    "    \n",
    "    # Generate the LaTeX table\n",
    "    average_epochs_used = df['average_epochs'].iloc[0] \n",
    "    caption_averaged =  \"\" if average_epochs_used == 0 else f\" averaged over {average_epochs_used} epochs\"\n",
    "    latex_table = latextable.draw_latex(\n",
    "        table, \n",
    "        caption=f\"Results for experiment {EXPERIMENT_GROUP}. All metrics calculated on field majority during validation phase{caption_averaged}, with mean and std reported. Best scores bold, second best underlined, $\\\\dagger$ is baseline.\", \n",
    "        label=f\"tab:metrics_comparison_{EXPERIMENT_GROUP}\", \n",
    "        use_booktabs=True,\n",
    "        position=\"h\"\n",
    "    )\n",
    "\n",
    "    # Add \\resizebox to the LaTeX table\n",
    "    latex_table = latex_table.replace('\\\\begin{center}', '\\\\begin{center}\\\\resizebox{\\\\textwidth}{!}{')\n",
    "    latex_table = latex_table.replace('\\\\end{center}', '}\\\\end{center}')\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Generate the LaTeX table\n",
    "df = pd.read_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\")\n",
    "df = df.sort_values(by='setup')\n",
    "\n",
    "# Optional: Drop rows to exclude some setups\n",
    "df = df.drop(EXCLUDED_SETUPS)\n",
    "\n",
    "latex_table = create_latex_table(df, baseline_setup=BASELINE_SETUP, first_n_metrics=FIRST_N_METRICS)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deserialize best_steps column in df to list\n",
    "df['best_steps'] = df['best_steps'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std for each list in column best_steps\n",
    "df['best_steps_mean'] = df['best_steps'].apply(np.mean)\n",
    "df['best_steps_std'] = df['best_steps'].apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>best_steps_mean</th>\n",
       "      <th>best_steps_std</th>\n",
       "      <th>num_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seasonality</td>\n",
       "      <td>1748.4</td>\n",
       "      <td>140.269170</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seasonality-reduced</td>\n",
       "      <td>2590.2</td>\n",
       "      <td>124.066756</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zueri_crop</td>\n",
       "      <td>1913.2</td>\n",
       "      <td>464.239335</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 setup  best_steps_mean  best_steps_std  num_runs\n",
       "2          seasonality           1748.4      140.269170         5\n",
       "1  seasonality-reduced           2590.2      124.066756         5\n",
       "0           zueri_crop           1913.2      464.239335         5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show columns setup, best_steps_mean and num_runs\n",
    "df[['setup', 'best_steps_mean', 'best_steps_std', 'num_runs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messis-bV8Bs8aq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
