{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import texttable as tt\n",
    "import latextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_GROUP = \"exp-1-dataset-split-strategy\"\n",
    "BASELINE_SETUP = \"random\"\n",
    "AVERAGE_EPOCHS = 5 # or None | must be odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 runs for experiment group 'exp-1-dataset-split-strategy'\n",
      "Run https://wandb.ai/crop-classification/messis/runs/tmmtb4ce - Missing 'name' in config, getting it from 'experiment_name' instead: random\n",
      "Run https://wandb.ai/crop-classification/messis/runs/04lknbug - Missing 'name' in config, getting it from 'experiment_name' instead: random\n",
      "Setup 'stratified-longer' - 1 runs\n",
      "Setup 'stratified-long' - 1 runs\n",
      "Setup 'sechidis' - 5 runs\n",
      "Setup 'random' - 5 runs\n",
      "Setup 'bands' - 5 runs\n",
      "Setup 'stratified' - 5 runs\n",
      "Run https://wandb.ai/crop-classification/messis/runs/islwn1g7 - Best epoch: 7434 (averaged over 5) - val_f1_tier3_majority: 0.18139490187168122\n",
      "Run https://wandb.ai/crop-classification/messis/runs/1wx9c8fy - Best epoch: 2064 (averaged over 5) - val_f1_tier3_majority: 0.14408288151025772\n",
      "Run https://wandb.ai/crop-classification/messis/runs/lfj8cwu4 - Best epoch: 1050 (averaged over 5) - val_f1_tier3_majority: 0.09199657291173935\n",
      "Run https://wandb.ai/crop-classification/messis/runs/hmm1uo25 - Best epoch: 1021 (averaged over 5) - val_f1_tier3_majority: 0.0826190710067749\n",
      "Run https://wandb.ai/crop-classification/messis/runs/a42lq9q5 - Best epoch: 1122 (averaged over 5) - val_f1_tier3_majority: 0.10170361548662185\n",
      "Run https://wandb.ai/crop-classification/messis/runs/kstftel1 - Best epoch: 1103 (averaged over 5) - val_f1_tier3_majority: 0.10661455057561398\n",
      "Run https://wandb.ai/crop-classification/messis/runs/eyy303wc - Best epoch: 1109 (averaged over 5) - val_f1_tier3_majority: 0.08777671307325363\n",
      "Run https://wandb.ai/crop-classification/messis/runs/tmmtb4ce - Best epoch: 1187 (averaged over 5) - val_f1_tier3_majority: 0.1189478263258934\n",
      "Run https://wandb.ai/crop-classification/messis/runs/04lknbug - Best epoch: 1498 (averaged over 5) - val_f1_tier3_majority: 0.11115802576144536\n",
      "Run https://wandb.ai/crop-classification/messis/runs/qj4o4ati - Best epoch: 1326 (averaged over 5) - val_f1_tier3_majority: 0.114912415544192\n",
      "Run https://wandb.ai/crop-classification/messis/runs/2zgnr3fw - Best epoch: 1247 (averaged over 5) - val_f1_tier3_majority: 0.11054254074891408\n",
      "Run https://wandb.ai/crop-classification/messis/runs/mudkttvj - Best epoch: 1065 (averaged over 5) - val_f1_tier3_majority: 0.07420322299003601\n",
      "Run https://wandb.ai/crop-classification/messis/runs/fyumjoqi - Best epoch: 740 (averaged over 5) - val_f1_tier3_majority: 0.06296094506978989\n",
      "Run https://wandb.ai/crop-classification/messis/runs/4nu14ssi - Best epoch: 1392 (averaged over 5) - val_f1_tier3_majority: 0.11554881557822227\n",
      "Run https://wandb.ai/crop-classification/messis/runs/lzkvcm2x - Best epoch: 1520 (averaged over 5) - val_f1_tier3_majority: 0.11592244356870651\n",
      "Run https://wandb.ai/crop-classification/messis/runs/mc68cdlz - Best epoch: 899 (averaged over 5) - val_f1_tier3_majority: 0.08505052328109741\n",
      "Run https://wandb.ai/crop-classification/messis/runs/blfh8ee4 - Best epoch: 869 (averaged over 5) - val_f1_tier3_majority: 0.11743244715034962\n",
      "Run https://wandb.ai/crop-classification/messis/runs/av80hhcp - Best epoch: 1119 (averaged over 5) - val_f1_tier3_majority: 0.08438099920749664\n",
      "Run https://wandb.ai/crop-classification/messis/runs/lf9khgx7 - Best epoch: 1073 (averaged over 5) - val_f1_tier3_majority: 0.09147921577095985\n",
      "Run https://wandb.ai/crop-classification/messis/runs/8591uumk - Best epoch: 1056 (averaged over 5) - val_f1_tier3_majority: 0.09565572999417782\n",
      "Run https://wandb.ai/crop-classification/messis/runs/f8oi85s8 - Best epoch: 1201 (averaged over 5) - val_f1_tier3_majority: 0.09669695297876994\n",
      "Run https://wandb.ai/crop-classification/messis/runs/vjyei1p5 - Best epoch: 816 (averaged over 5) - val_f1_tier3_majority: 0.07804033383727074\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>num_runs</th>\n",
       "      <th>average_epochs</th>\n",
       "      <th>run_handles</th>\n",
       "      <th>best_steps</th>\n",
       "      <th>val_f1_tier1_majority_mean</th>\n",
       "      <th>val_f1_tier1_majority_std</th>\n",
       "      <th>val_f1_tier2_majority_mean</th>\n",
       "      <th>val_f1_tier2_majority_std</th>\n",
       "      <th>val_f1_tier3_majority_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>val_recall_tier2_majority_mean</th>\n",
       "      <th>val_recall_tier2_majority_std</th>\n",
       "      <th>val_recall_tier3_majority_mean</th>\n",
       "      <th>val_recall_tier3_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stratified-longer</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[islwn1g7]</td>\n",
       "      <td>[7434]</td>\n",
       "      <td>0.381075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.677414</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stratified-long</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[1wx9c8fy]</td>\n",
       "      <td>[2064]</td>\n",
       "      <td>0.399910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.852520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648562</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sechidis</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[lfj8cwu4, hmm1uo25, a42lq9q5, kstftel1, eyy30...</td>\n",
       "      <td>[1050, 1021, 1122, 1103, 1109]</td>\n",
       "      <td>0.378196</td>\n",
       "      <td>0.031965</td>\n",
       "      <td>0.211349</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.094142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214312</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>0.102784</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>0.810183</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>0.629465</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>0.558674</td>\n",
       "      <td>0.018702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[tmmtb4ce, 04lknbug, qj4o4ati, 2zgnr3fw, mudkt...</td>\n",
       "      <td>[1187, 1498, 1326, 1247, 1065]</td>\n",
       "      <td>0.403428</td>\n",
       "      <td>0.057137</td>\n",
       "      <td>0.220351</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.105953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226245</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.113676</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.645091</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>0.575700</td>\n",
       "      <td>0.023932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bands</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[fyumjoqi, 4nu14ssi, lzkvcm2x, mc68cdlz, blfh8...</td>\n",
       "      <td>[740, 1392, 1520, 899, 869]</td>\n",
       "      <td>0.384699</td>\n",
       "      <td>0.061576</td>\n",
       "      <td>0.218879</td>\n",
       "      <td>0.028843</td>\n",
       "      <td>0.099383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228762</td>\n",
       "      <td>0.023233</td>\n",
       "      <td>0.110627</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.789356</td>\n",
       "      <td>0.018374</td>\n",
       "      <td>0.615074</td>\n",
       "      <td>0.054720</td>\n",
       "      <td>0.538760</td>\n",
       "      <td>0.059415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stratified</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[av80hhcp, lf9khgx7, 8591uumk, f8oi85s8, vjyei...</td>\n",
       "      <td>[1119, 1073, 1056, 1201, 816]</td>\n",
       "      <td>0.378024</td>\n",
       "      <td>0.023070</td>\n",
       "      <td>0.208712</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.089251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212239</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.097254</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.810463</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.627513</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.545880</td>\n",
       "      <td>0.020874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               setup  num_runs  average_epochs  \\\n",
       "0  stratified-longer         1               5   \n",
       "1    stratified-long         1               5   \n",
       "2           sechidis         5               5   \n",
       "3             random         5               5   \n",
       "4              bands         5               5   \n",
       "5         stratified         5               5   \n",
       "\n",
       "                                         run_handles  \\\n",
       "0                                         [islwn1g7]   \n",
       "1                                         [1wx9c8fy]   \n",
       "2  [lfj8cwu4, hmm1uo25, a42lq9q5, kstftel1, eyy30...   \n",
       "3  [tmmtb4ce, 04lknbug, qj4o4ati, 2zgnr3fw, mudkt...   \n",
       "4  [fyumjoqi, 4nu14ssi, lzkvcm2x, mc68cdlz, blfh8...   \n",
       "5  [av80hhcp, lf9khgx7, 8591uumk, f8oi85s8, vjyei...   \n",
       "\n",
       "                       best_steps  val_f1_tier1_majority_mean  \\\n",
       "0                          [7434]                    0.381075   \n",
       "1                          [2064]                    0.399910   \n",
       "2  [1050, 1021, 1122, 1103, 1109]                    0.378196   \n",
       "3  [1187, 1498, 1326, 1247, 1065]                    0.403428   \n",
       "4     [740, 1392, 1520, 899, 869]                    0.384699   \n",
       "5   [1119, 1073, 1056, 1201, 816]                    0.378024   \n",
       "\n",
       "   val_f1_tier1_majority_std  val_f1_tier2_majority_mean  \\\n",
       "0                   0.000000                    0.267287   \n",
       "1                   0.000000                    0.264600   \n",
       "2                   0.031965                    0.211349   \n",
       "3                   0.057137                    0.220351   \n",
       "4                   0.061576                    0.218879   \n",
       "5                   0.023070                    0.208712   \n",
       "\n",
       "   val_f1_tier2_majority_std  val_f1_tier3_majority_mean  ...  \\\n",
       "0                   0.000000                    0.181395  ...   \n",
       "1                   0.000000                    0.144083  ...   \n",
       "2                   0.014070                    0.094142  ...   \n",
       "3                   0.019427                    0.105953  ...   \n",
       "4                   0.028843                    0.099383  ...   \n",
       "5                   0.009237                    0.089251  ...   \n",
       "\n",
       "   val_recall_tier2_majority_mean  val_recall_tier2_majority_std  \\\n",
       "0                        0.256731                       0.000000   \n",
       "1                        0.261352                       0.000000   \n",
       "2                        0.214312                       0.012374   \n",
       "3                        0.226245                       0.017065   \n",
       "4                        0.228762                       0.023233   \n",
       "5                        0.212239                       0.006696   \n",
       "\n",
       "   val_recall_tier3_majority_mean  val_recall_tier3_majority_std  \\\n",
       "0                        0.174624                       0.000000   \n",
       "1                        0.150909                       0.000000   \n",
       "2                        0.102784                       0.007650   \n",
       "3                        0.113676                       0.013620   \n",
       "4                        0.110627                       0.016543   \n",
       "5                        0.097254                       0.006759   \n",
       "\n",
       "   val_cohen_kappa_tier1_majority_mean  val_cohen_kappa_tier1_majority_std  \\\n",
       "0                             0.866521                            0.000000   \n",
       "1                             0.852520                            0.000000   \n",
       "2                             0.810183                            0.032170   \n",
       "3                             0.816497                            0.027777   \n",
       "4                             0.789356                            0.018374   \n",
       "5                             0.810463                            0.014770   \n",
       "\n",
       "   val_cohen_kappa_tier2_majority_mean  val_cohen_kappa_tier2_majority_std  \\\n",
       "0                             0.721650                            0.000000   \n",
       "1                             0.702697                            0.000000   \n",
       "2                             0.629465                            0.018179   \n",
       "3                             0.645091                            0.021135   \n",
       "4                             0.615074                            0.054720   \n",
       "5                             0.627513                            0.011822   \n",
       "\n",
       "   val_cohen_kappa_tier3_majority_mean  val_cohen_kappa_tier3_majority_std  \n",
       "0                             0.677414                            0.000000  \n",
       "1                             0.648562                            0.000000  \n",
       "2                             0.558674                            0.018702  \n",
       "3                             0.575700                            0.023932  \n",
       "4                             0.538760                            0.059415  \n",
       "5                             0.545880                            0.020874  \n",
       "\n",
       "[6 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_epoch_metrics(run, metric_name, average_epochs=None):\n",
    "    history = run.history(samples=10000)\n",
    "    \n",
    "    # Find the epoch with the best metric value\n",
    "    best_epoch = history[metric_name].idxmax()\n",
    "    best_metrics = history.loc[best_epoch]\n",
    "    \n",
    "    if average_epochs:\n",
    "        # Find indices of valid (non-NaN) values\n",
    "        valid_indices = history[metric_name].dropna().index\n",
    "        \n",
    "        # Locate the best epoch index in the valid indices\n",
    "        best_index_position = valid_indices.get_loc(best_epoch)\n",
    "        \n",
    "        # Get the indices of the AVERAGE_EPOCHS epochs to be averaged\n",
    "        idx_adjustment = (average_epochs - 1) // 2\n",
    "        start_index = max(0, best_index_position - idx_adjustment)\n",
    "        end_index = min(len(valid_indices), best_index_position + idx_adjustment + 1)\n",
    "        selected_indices = valid_indices[start_index:end_index]\n",
    "        \n",
    "        # Average the metrics over the selected epochs\n",
    "        averaged_metrics = history.loc[selected_indices].mean()\n",
    "        \n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} (averaged over {average_epochs}) - {metric_name}: {averaged_metrics[metric_name]}\")\n",
    "        return averaged_metrics, best_epoch\n",
    "    else:\n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} - {metric_name}: {best_metrics[metric_name]}\")\n",
    "        return best_metrics, best_epoch\n",
    "\n",
    "def gather_metrics_for_experiment_group(experiment_group, average_epochs=False, has_weighted_accuracy=True):\n",
    "    api = wandb.Api()\n",
    "\n",
    "    # Fetch runs matching the experiment group\n",
    "    runs = api.runs(\"crop-classification/messis\", filters={\"config.experiment_group\": experiment_group})\n",
    "    print(f\"Found {len(runs)} runs for experiment group '{experiment_group}'\")\n",
    "\n",
    "    # Organize the runs by setup name\n",
    "    setups = {}\n",
    "    for run in runs:\n",
    "        if 'name' not in run.config:\n",
    "            if 'experiment_name' in run.config:\n",
    "                setup_name = run.config['experiment_name'].split('-')[-1]\n",
    "                print(f\"Run {run.url} - Missing 'name' in config, getting it from 'experiment_name' instead: {setup_name}\")\n",
    "            else:\n",
    "                print(f\"Run {run.url} - Missing 'name' in config, skipping\")\n",
    "                continue\n",
    "        else:\n",
    "            setup_name = run.config['name']\n",
    "        if setup_name not in setups:\n",
    "            setups[setup_name] = {\n",
    "                'runs': [],\n",
    "                'metrics': {metric: [] for metric in [\n",
    "                    'val_f1_tier1_majority',\n",
    "                    'val_f1_tier2_majority',\n",
    "                    'val_f1_tier3_majority',\n",
    "                    'val_weighted_accuracy_tier1_majority' if has_weighted_accuracy else 'val_accuracy_tier1_majority',\n",
    "                    'val_weighted_accuracy_tier2_majority' if has_weighted_accuracy else 'val_accuracy_tier2_majority',\n",
    "                    'val_weighted_accuracy_tier3_majority' if has_weighted_accuracy else 'val_accuracy_tier3_majority',\n",
    "                    'val_precision_tier1_majority',\n",
    "                    'val_precision_tier2_majority',\n",
    "                    'val_precision_tier3_majority',\n",
    "                    'val_recall_tier1_majority',\n",
    "                    'val_recall_tier2_majority',\n",
    "                    'val_recall_tier3_majority',\n",
    "                    'val_cohen_kappa_tier1_majority',\n",
    "                    'val_cohen_kappa_tier2_majority',\n",
    "                    'val_cohen_kappa_tier3_majority',\n",
    "                ]},\n",
    "                'best_steps': []\n",
    "            }\n",
    "        setups[setup_name]['runs'].append(run)\n",
    "\n",
    "    # Print setup names with number of runs\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        print(f\"Setup '{setup_name}' - {len(setup_data['runs'])} runs\")\n",
    "\n",
    "    # Gather metrics for each setup\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        for run in setup_data['runs']:\n",
    "            best_metrics, best_epoch = get_best_epoch_metrics(run, 'val_f1_tier3_majority', average_epochs)\n",
    "            setup_data['best_steps'].append(best_epoch)\n",
    "            for metric in setup_data['metrics']:\n",
    "                setup_data['metrics'][metric].append(best_metrics[metric])\n",
    "    \n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        metrics_summary = {\n",
    "            'setup': setup_name,\n",
    "            'num_runs': len(setup_data['runs']),\n",
    "            'average_epochs': average_epochs,\n",
    "            'run_handles': [run.id for run in setup_data['runs']],\n",
    "            'best_steps': setup_data['best_steps'],\n",
    "        }\n",
    "        for metric, values in setup_data['metrics'].items():\n",
    "            metrics_summary[f'{metric}_mean'] = np.mean(values)\n",
    "            metrics_summary[f'{metric}_std'] = np.std(values)\n",
    "        data.append(metrics_summary)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(data)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Run the function for a given experiment group\n",
    "metrics_df = gather_metrics_for_experiment_group(EXPERIMENT_GROUP, average_epochs=AVERAGE_EPOCHS)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\", index=False)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\t\\begin{center}\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{lcccccc}\n",
      "\t\t\t\\toprule\n",
      "\t\t\tMetric & $\\dagger$ random (5-fold) & bands (5-fold) & sechidis (5-fold) & stratified (5-fold) & stratified-long (1-fold) & stratified-longer (1-fold) \\\\\n",
      "\t\t\t\\midrule\n",
      "\t\t\tF1 $T_1$ & \\textbf{40.3\\% ± 5.7\\%} & 38.5\\% ± 6.2\\% & 37.8\\% ± 3.2\\% & 37.8\\% ± 2.3\\% & \\underline{40.0\\% ± 0.0\\%} & 38.1\\% ± 0.0\\% \\\\\n",
      "\t\t\tF1 $T_2$ & 22.0\\% ± 1.9\\% & 21.9\\% ± 2.9\\% & 21.1\\% ± 1.4\\% & 20.9\\% ± 0.9\\% & \\underline{26.5\\% ± 0.0\\%} & \\textbf{26.7\\% ± 0.0\\%} \\\\\n",
      "\t\t\tF1 $T_3$ & 10.6\\% ± 1.6\\% & 9.9\\% ± 2.2\\% & 9.4\\% ± 0.9\\% & 8.9\\% ± 0.7\\% & \\underline{14.4\\% ± 0.0\\%} & \\textbf{18.1\\% ± 0.0\\%} \\\\\n",
      "\t\t\tAcc. $T_1$ & \\textbf{40.7\\% ± 5.5\\%} & 38.8\\% ± 5.8\\% & 36.9\\% ± 2.8\\% & 37.3\\% ± 2.3\\% & \\underline{39.4\\% ± 0.0\\%} & 35.9\\% ± 0.0\\% \\\\\n",
      "\t\t\tAcc. $T_2$ & 22.6\\% ± 1.7\\% & 22.9\\% ± 2.3\\% & 21.4\\% ± 1.2\\% & 21.2\\% ± 0.7\\% & \\textbf{26.1\\% ± 0.0\\%} & \\underline{25.7\\% ± 0.0\\%} \\\\\n",
      "\t\t\tAcc. $T_3$ & 11.4\\% ± 1.4\\% & 11.1\\% ± 1.7\\% & 10.3\\% ± 0.8\\% & 9.7\\% ± 0.7\\% & \\underline{15.1\\% ± 0.0\\%} & \\textbf{17.5\\% ± 0.0\\%} \\\\\n",
      "\t\t\t\\bottomrule\n",
      "\t\t\\end{tabular}\n",
      "\t}\\end{center}\n",
      "\t\\caption{Results for experiment exp-1-dataset-split-strategy. All metrics calculated on field majority during validation phase averaged over 5 epochs, with mean and std reported. Best scores bold, second best underlined, $\\dagger$ is baseline.}\n",
      "\t\\label{tab:metrics_comparison_exp-1-dataset-split-strategy}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Mapping for short metric names\n",
    "metric_name_mapping = {\n",
    "    'val_f1_tier1_majority': 'F1 $T_1$',\n",
    "    'val_f1_tier2_majority': 'F1 $T_2$',\n",
    "    'val_f1_tier3_majority': 'F1 $T_3$',\n",
    "    'val_accuracy_tier1_majority': 'Acc. $T_1$',\n",
    "    'val_accuracy_tier2_majority': 'Acc. $T_2$',\n",
    "    'val_accuracy_tier3_majority': 'Acc. $T_3$',\n",
    "    'val_weighted_accuracy_tier1_majority': 'W. Acc. $T_1$',\n",
    "    'val_weighted_accuracy_tier2_majority': 'W. Acc. $T_2$',\n",
    "    'val_weighted_accuracy_tier3_majority': 'W. Acc. $T_3$',\n",
    "    'val_precision_tier1_majority': 'Precision $T_1$',\n",
    "    'val_precision_tier2_majority': 'Precision $T_2$',\n",
    "    'val_precision_tier3_majority': 'Precision $T_3$',\n",
    "    'val_recall_tier1_majority': 'Recall $T_1$',\n",
    "    'val_recall_tier2_majority': 'Recall $T_2$',\n",
    "    'val_recall_tier3_majority': 'Recall $T_3$',\n",
    "    'val_cohen_kappa_tier1_majority': 'Kappa $T_1$',\n",
    "    'val_cohen_kappa_tier2_majority': 'Kappa $T_2$',\n",
    "    'val_cohen_kappa_tier3_majority': 'Kappa $T_3$',\n",
    "}\n",
    "\n",
    "# Function to create a LaTeX table with bold best scores and underlined second-best scores\n",
    "def create_latex_table(df, baseline_setup, first_n_metrics=None):\n",
    "    metrics = list(metric_name_mapping.keys())\n",
    "    if first_n_metrics:\n",
    "        metrics = metrics[:first_n_metrics]\n",
    "    \n",
    "    # Determine the best and second-best scores for each metric\n",
    "    best_scores = {metric: df[f'{metric}_mean'].max() for metric in metrics}\n",
    "    second_best_scores = {\n",
    "        metric: sorted(df[f'{metric}_mean'].unique(), reverse=True)[1] if len(df[f'{metric}_mean'].unique()) > 1 else None\n",
    "        for metric in metrics\n",
    "    }\n",
    "\n",
    "    # Reorder the dataframe to have the baseline setup first\n",
    "    df = df.set_index('setup')\n",
    "    if baseline_setup in df.index:\n",
    "        df = df.loc[[baseline_setup] + [idx for idx in df.index if idx != baseline_setup]].reset_index()\n",
    "    else:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    # Initialize the Texttable object\n",
    "    table = tt.Texttable()\n",
    "    \n",
    "    # Define the header\n",
    "    headers = ['Metric'] + [f\"{'$\\\\dagger$ ' if row['setup'] == baseline_setup else ''}{setup} ({row['num_runs']}-fold)\" \n",
    "                            for idx, row in df.iterrows() for setup in [row['setup']]]\n",
    "    table.header(headers)\n",
    "    \n",
    "    # Set alignment for columns\n",
    "    cols_align = [\"c\"] * len(headers)\n",
    "    cols_align[0] = \"l\"\n",
    "    table.set_cols_align(cols_align)\n",
    "    \n",
    "    # Populate the table with data\n",
    "    for metric in metrics:\n",
    "        row_data = [metric_name_mapping[metric]]\n",
    "        for idx, row in df.iterrows():\n",
    "            mean = row[f'{metric}_mean'] * 100\n",
    "            std = row[f'{metric}_std'] * 100\n",
    "            value = f'{mean:.1f}\\\\% ± {std:.1f}\\\\%'\n",
    "            if mean == best_scores[metric] * 100:\n",
    "                value = f'\\\\textbf{{{value}}}'\n",
    "            elif second_best_scores[metric] and mean == second_best_scores[metric] * 100:\n",
    "                value = f'\\\\underline{{{value}}}'\n",
    "            row_data.append(value)\n",
    "        table.add_row(row_data)\n",
    "    \n",
    "    # Generate the LaTeX table\n",
    "    average_epochs_used = df['average_epochs'].iloc[0]\n",
    "    caption_averaged =  f\"averaged over {average_epochs_used} epochs\" if average_epochs_used else \"\"\n",
    "    latex_table = latextable.draw_latex(\n",
    "        table, \n",
    "        caption=f\"Results for experiment {EXPERIMENT_GROUP}. All metrics calculated on field majority during validation phase {caption_averaged}, with mean and std reported. Best scores bold, second best underlined, $\\\\dagger$ is baseline.\", \n",
    "        label=f\"tab:metrics_comparison_{EXPERIMENT_GROUP}\", \n",
    "        use_booktabs=True,\n",
    "        position=\"h\"\n",
    "    )\n",
    "\n",
    "    # Add \\resizebox to the LaTeX table\n",
    "    latex_table = latex_table.replace('\\\\begin{center}', '\\\\begin{center}\\\\resizebox{\\\\textwidth}{!}{')\n",
    "    latex_table = latex_table.replace('\\\\end{center}', '}\\\\end{center}')\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Generate the LaTeX table\n",
    "df = pd.read_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\")\n",
    "df = df.sort_values(by='setup')\n",
    "\n",
    "# Optional: Drop rows to exclude some setups\n",
    "# df = df.drop([0, 1])\n",
    "\n",
    "latex_table = create_latex_table(df, baseline_setup=BASELINE_SETUP, first_n_metrics=6)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messis-bV8Bs8aq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
