{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import texttable as tt\n",
    "import latextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 runs for experiment group 'exp-9-dropout2d'\n",
      "Setup 'p-0.5' - 1 runs\n",
      "Setup 'p-0.2' - 5 runs\n",
      "Setup 'refhead-zuericrop' - 5 runs\n",
      "Setup 'p-0.1' - 5 runs\n",
      "Run https://wandb.ai/crop-classification/messis/runs/cm0hlw6k - Best epoch: 4858 (averaged over 5) - val_f1_tier3_majority: 0.19199746549129487\n",
      "Run https://wandb.ai/crop-classification/messis/runs/rouv9lch - Best epoch: 2446 (averaged over 5) - val_f1_tier3_majority: 0.17942703366279603\n",
      "Run https://wandb.ai/crop-classification/messis/runs/ym9requx - Best epoch: 2697 (averaged over 5) - val_f1_tier3_majority: 0.1837272971868515\n",
      "Run https://wandb.ai/crop-classification/messis/runs/6hsyjfm2 - Best epoch: 3250 (averaged over 5) - val_f1_tier3_majority: 0.1891927808523178\n",
      "Run https://wandb.ai/crop-classification/messis/runs/qhqbesf6 - Best epoch: 3300 (averaged over 5) - val_f1_tier3_majority: 0.199286550283432\n",
      "Run https://wandb.ai/crop-classification/messis/runs/d3zidx38 - Best epoch: 3300 (averaged over 5) - val_f1_tier3_majority: 0.20499715805053711\n",
      "Run https://wandb.ai/crop-classification/messis/runs/6vdvcpsa - Best epoch: 2999 (averaged over 5) - val_f1_tier3_majority: 0.18511748015880586\n",
      "Run https://wandb.ai/crop-classification/messis/runs/voz39aqw - Best epoch: 3350 (averaged over 5) - val_f1_tier3_majority: 0.1903060108423233\n",
      "Run https://wandb.ai/crop-classification/messis/runs/tzbb1fpf - Best epoch: 3099 (averaged over 5) - val_f1_tier3_majority: 0.19846892058849336\n",
      "Run https://wandb.ai/crop-classification/messis/runs/yfrzmegx - Best epoch: 2496 (averaged over 5) - val_f1_tier3_majority: 0.1986322969198227\n",
      "Run https://wandb.ai/crop-classification/messis/runs/mhanp2qr - Best epoch: 2496 (averaged over 5) - val_f1_tier3_majority: 0.1927913874387741\n",
      "Run https://wandb.ai/crop-classification/messis/runs/lrt47pea - Best epoch: 3551 (averaged over 5) - val_f1_tier3_majority: 0.1907111346721649\n",
      "Run https://wandb.ai/crop-classification/messis/runs/sft8i5l2 - Best epoch: 3401 (averaged over 5) - val_f1_tier3_majority: 0.19627068638801576\n",
      "Run https://wandb.ai/crop-classification/messis/runs/hflukrac - Best epoch: 3953 (averaged over 5) - val_f1_tier3_majority: 0.2011514961719513\n",
      "Run https://wandb.ai/crop-classification/messis/runs/il64btbr - Best epoch: 2496 (averaged over 5) - val_f1_tier3_majority: 0.19764536023139953\n",
      "Run https://wandb.ai/crop-classification/messis/runs/9nyrx2k7 - Best epoch: 2345 (averaged over 5) - val_f1_tier3_majority: 0.19477352797985076\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>num_runs</th>\n",
       "      <th>average_epochs</th>\n",
       "      <th>run_handles</th>\n",
       "      <th>best_steps</th>\n",
       "      <th>val_f1_tier1_majority_mean</th>\n",
       "      <th>val_f1_tier1_majority_std</th>\n",
       "      <th>val_f1_tier2_majority_mean</th>\n",
       "      <th>val_f1_tier2_majority_std</th>\n",
       "      <th>val_f1_tier3_majority_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>val_recall_tier2_majority_mean</th>\n",
       "      <th>val_recall_tier2_majority_std</th>\n",
       "      <th>val_recall_tier3_majority_mean</th>\n",
       "      <th>val_recall_tier3_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier1_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier2_majority_std</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_mean</th>\n",
       "      <th>val_cohen_kappa_tier3_majority_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[cm0hlw6k]</td>\n",
       "      <td>[4858]</td>\n",
       "      <td>0.363116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703745</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p-0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[rouv9lch, ym9requx, 6hsyjfm2, qhqbesf6, d3zid...</td>\n",
       "      <td>[2446, 2697, 3250, 3300, 3300]</td>\n",
       "      <td>0.461478</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>0.304173</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>0.191326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298009</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>0.184921</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.863881</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.740391</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.687420</td>\n",
       "      <td>0.008463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>refhead-zuericrop</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[6vdvcpsa, voz39aqw, tzbb1fpf, yfrzmegx, mhanp...</td>\n",
       "      <td>[2999, 3350, 3099, 2496, 2496]</td>\n",
       "      <td>0.447482</td>\n",
       "      <td>0.050752</td>\n",
       "      <td>0.301528</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.193063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.186544</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.861531</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.737542</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>0.685056</td>\n",
       "      <td>0.008471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p-0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[lrt47pea, sft8i5l2, hflukrac, il64btbr, 9nyrx...</td>\n",
       "      <td>[3551, 3401, 3953, 2496, 2345]</td>\n",
       "      <td>0.460275</td>\n",
       "      <td>0.043490</td>\n",
       "      <td>0.304586</td>\n",
       "      <td>0.009983</td>\n",
       "      <td>0.196110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298495</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>0.188820</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.864783</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.739495</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.686381</td>\n",
       "      <td>0.010797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               setup  num_runs  average_epochs  \\\n",
       "0              p-0.5         1               5   \n",
       "1              p-0.2         5               5   \n",
       "2  refhead-zuericrop         5               5   \n",
       "3              p-0.1         5               5   \n",
       "\n",
       "                                         run_handles  \\\n",
       "0                                         [cm0hlw6k]   \n",
       "1  [rouv9lch, ym9requx, 6hsyjfm2, qhqbesf6, d3zid...   \n",
       "2  [6vdvcpsa, voz39aqw, tzbb1fpf, yfrzmegx, mhanp...   \n",
       "3  [lrt47pea, sft8i5l2, hflukrac, il64btbr, 9nyrx...   \n",
       "\n",
       "                       best_steps  val_f1_tier1_majority_mean  \\\n",
       "0                          [4858]                    0.363116   \n",
       "1  [2446, 2697, 3250, 3300, 3300]                    0.461478   \n",
       "2  [2999, 3350, 3099, 2496, 2496]                    0.447482   \n",
       "3  [3551, 3401, 3953, 2496, 2345]                    0.460275   \n",
       "\n",
       "   val_f1_tier1_majority_std  val_f1_tier2_majority_mean  \\\n",
       "0                   0.000000                    0.273813   \n",
       "1                   0.040348                    0.304173   \n",
       "2                   0.050752                    0.301528   \n",
       "3                   0.043490                    0.304586   \n",
       "\n",
       "   val_f1_tier2_majority_std  val_f1_tier3_majority_mean  ...  \\\n",
       "0                   0.000000                    0.191997  ...   \n",
       "1                   0.009767                    0.191326  ...   \n",
       "2                   0.012916                    0.193063  ...   \n",
       "3                   0.009983                    0.196110  ...   \n",
       "\n",
       "   val_recall_tier2_majority_mean  val_recall_tier2_majority_std  \\\n",
       "0                        0.266054                       0.000000   \n",
       "1                        0.298009                       0.011831   \n",
       "2                        0.294862                       0.014609   \n",
       "3                        0.298495                       0.010265   \n",
       "\n",
       "   val_recall_tier3_majority_mean  val_recall_tier3_majority_std  \\\n",
       "0                        0.184392                       0.000000   \n",
       "1                        0.184921                       0.008820   \n",
       "2                        0.186544                       0.006217   \n",
       "3                        0.188820                       0.002574   \n",
       "\n",
       "   val_cohen_kappa_tier1_majority_mean  val_cohen_kappa_tier1_majority_std  \\\n",
       "0                             0.871411                            0.000000   \n",
       "1                             0.863881                            0.007791   \n",
       "2                             0.861531                            0.005354   \n",
       "3                             0.864783                            0.006117   \n",
       "\n",
       "   val_cohen_kappa_tier2_majority_mean  val_cohen_kappa_tier2_majority_std  \\\n",
       "0                             0.747432                            0.000000   \n",
       "1                             0.740391                            0.007973   \n",
       "2                             0.737542                            0.007518   \n",
       "3                             0.739495                            0.007982   \n",
       "\n",
       "   val_cohen_kappa_tier3_majority_mean  val_cohen_kappa_tier3_majority_std  \n",
       "0                             0.703745                            0.000000  \n",
       "1                             0.687420                            0.008463  \n",
       "2                             0.685056                            0.008471  \n",
       "3                             0.686381                            0.010797  \n",
       "\n",
       "[4 rows x 35 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_GROUP = \"exp-9-dropout2d\"\n",
    "AVERAGE_EPOCHS = 5 #Â or None | must be odd\n",
    "\n",
    "def get_best_epoch_metrics(run, metric_name, average_epochs=None):\n",
    "    history = run.history(samples=10000)\n",
    "    \n",
    "    # Find the epoch with the best metric value\n",
    "    best_epoch = history[metric_name].idxmax()\n",
    "    best_metrics = history.loc[best_epoch]\n",
    "    \n",
    "    if average_epochs:\n",
    "        # Find indices of valid (non-NaN) values\n",
    "        valid_indices = history[metric_name].dropna().index\n",
    "        \n",
    "        # Locate the best epoch index in the valid indices\n",
    "        best_index_position = valid_indices.get_loc(best_epoch)\n",
    "        \n",
    "        # Get the indices of the AVERAGE_EPOCHS epochs to be averaged\n",
    "        idx_adjustment = (average_epochs - 1) // 2\n",
    "        start_index = max(0, best_index_position - idx_adjustment)\n",
    "        end_index = min(len(valid_indices), best_index_position + idx_adjustment + 1)\n",
    "        selected_indices = valid_indices[start_index:end_index]\n",
    "        \n",
    "        # Average the metrics over the selected epochs\n",
    "        averaged_metrics = history.loc[selected_indices].mean()\n",
    "        \n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} (averaged over {average_epochs}) - {metric_name}: {averaged_metrics[metric_name]}\")\n",
    "        return averaged_metrics, best_epoch\n",
    "    else:\n",
    "        print(f\"Run {run.url} - Best epoch: {best_epoch} - {metric_name}: {best_metrics[metric_name]}\")\n",
    "        return best_metrics, best_epoch\n",
    "\n",
    "def gather_metrics_for_experiment_group(experiment_group, average_epochs=False):\n",
    "    api = wandb.Api()\n",
    "\n",
    "    # Fetch runs matching the experiment group\n",
    "    runs = api.runs(\"crop-classification/messis\", filters={\"config.experiment_group\": experiment_group})\n",
    "    print(f\"Found {len(runs)} runs for experiment group '{experiment_group}'\")\n",
    "\n",
    "    # Organize the runs by setup name\n",
    "    setups = {}\n",
    "    for run in runs:\n",
    "        setup_name = run.config['name']\n",
    "        if setup_name not in setups:\n",
    "            setups[setup_name] = {\n",
    "                'runs': [],\n",
    "                'metrics': {metric: [] for metric in [\n",
    "                    'val_f1_tier1_majority',\n",
    "                    'val_f1_tier2_majority',\n",
    "                    'val_f1_tier3_majority',\n",
    "                    'val_weighted_accuracy_tier1_majority',\n",
    "                    'val_weighted_accuracy_tier2_majority',\n",
    "                    'val_weighted_accuracy_tier3_majority',\n",
    "                    'val_precision_tier1_majority',\n",
    "                    'val_precision_tier2_majority',\n",
    "                    'val_precision_tier3_majority',\n",
    "                    'val_recall_tier1_majority',\n",
    "                    'val_recall_tier2_majority',\n",
    "                    'val_recall_tier3_majority',\n",
    "                    'val_cohen_kappa_tier1_majority',\n",
    "                    'val_cohen_kappa_tier2_majority',\n",
    "                    'val_cohen_kappa_tier3_majority',\n",
    "                ]},\n",
    "                'best_steps': []\n",
    "            }\n",
    "        setups[setup_name]['runs'].append(run)\n",
    "\n",
    "    # Print setup names with number of runs\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        print(f\"Setup '{setup_name}' - {len(setup_data['runs'])} runs\")\n",
    "\n",
    "    # Gather metrics for each setup\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        for run in setup_data['runs']:\n",
    "            best_metrics, best_epoch = get_best_epoch_metrics(run, 'val_f1_tier3_majority', average_epochs)\n",
    "            setup_data['best_steps'].append(best_epoch)\n",
    "            for metric in setup_data['metrics']:\n",
    "                setup_data['metrics'][metric].append(best_metrics[metric])\n",
    "    \n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "    for setup_name, setup_data in setups.items():\n",
    "        metrics_summary = {\n",
    "            'setup': setup_name,\n",
    "            'num_runs': len(setup_data['runs']),\n",
    "            'average_epochs': average_epochs,\n",
    "            'run_handles': [run.id for run in setup_data['runs']],\n",
    "            'best_steps': setup_data['best_steps'],\n",
    "        }\n",
    "        for metric, values in setup_data['metrics'].items():\n",
    "            metrics_summary[f'{metric}_mean'] = np.mean(values)\n",
    "            metrics_summary[f'{metric}_std'] = np.std(values)\n",
    "        data.append(metrics_summary)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(data)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Run the function for a given experiment group\n",
    "metrics_df = gather_metrics_for_experiment_group(EXPERIMENT_GROUP, average_epochs=AVERAGE_EPOCHS)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\", index=False)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\t\\begin{center}\\resizebox{\\textwidth}{!}{\n",
      "\t\t\\begin{tabular}{lcccc}\n",
      "\t\t\t\\toprule\n",
      "\t\t\tMetric & p-0.1 (5-fold) & p-0.2 (5-fold) & p-0.5 (1-fold) & refhead-zuericrop (5-fold) \\\\\n",
      "\t\t\t\\midrule\n",
      "\t\t\tF1 $T_1$ & 46.0\\% Â± 4.3\\% & \\textbf{46.1\\% Â± 4.0\\%} & 36.3\\% Â± 0.0\\% & 44.7\\% Â± 5.1\\% \\\\\n",
      "\t\t\tF1 $T_2$ & \\textbf{30.5\\% Â± 1.0\\%} & 30.4\\% Â± 1.0\\% & 27.4\\% Â± 0.0\\% & 30.2\\% Â± 1.3\\% \\\\\n",
      "\t\t\tF1 $T_3$ & \\textbf{19.6\\% Â± 0.3\\%} & 19.1\\% Â± 1.0\\% & 19.2\\% Â± 0.0\\% & 19.3\\% Â± 0.5\\% \\\\\n",
      "\t\t\tW. Acc. $T_1$ & 93.1\\% Â± 0.3\\% & 93.1\\% Â± 0.4\\% & \\textbf{93.5\\% Â± 0.0\\%} & 93.0\\% Â± 0.3\\% \\\\\n",
      "\t\t\tW. Acc. $T_2$ & 82.1\\% Â± 0.6\\% & 82.2\\% Â± 0.6\\% & \\textbf{82.7\\% Â± 0.0\\%} & 82.0\\% Â± 0.6\\% \\\\\n",
      "\t\t\tW. Acc. $T_3$ & 77.7\\% Â± 0.8\\% & 77.8\\% Â± 0.6\\% & \\textbf{78.9\\% Â± 0.0\\%} & 77.6\\% Â± 0.6\\% \\\\\n",
      "\t\t\t\\bottomrule\n",
      "\t\t\\end{tabular}\n",
      "\t}\\end{center}\n",
      "\t\\caption{Results for experiment exp-9-dropout2d. All metrics calculated on field majority during validation phase averaged over 5 epochs, with mean and std reported. Best scores shown in bold.}\n",
      "\t\\label{tab:metrics_comparison_exp-9-dropout2d}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"experiment_results/eval_{EXPERIMENT_GROUP}.csv\")\n",
    "\n",
    "df = df.sort_values(by='setup')\n",
    "\n",
    "# Mapping for short metric names\n",
    "metric_name_mapping = {\n",
    "    'val_f1_tier1_majority': 'F1 $T_1$',\n",
    "    'val_f1_tier2_majority': 'F1 $T_2$',\n",
    "    'val_f1_tier3_majority': 'F1 $T_3$',\n",
    "    'val_weighted_accuracy_tier1_majority': 'W. Acc. $T_1$',\n",
    "    'val_weighted_accuracy_tier2_majority': 'W. Acc. $T_2$',\n",
    "    'val_weighted_accuracy_tier3_majority': 'W. Acc. $T_3$',\n",
    "    'val_precision_tier1_majority': 'Precision $T_1$',\n",
    "    'val_precision_tier2_majority': 'Precision $T_2$',\n",
    "    'val_precision_tier3_majority': 'Precision $T_3$',\n",
    "    'val_recall_tier1_majority': 'Recall $T_1$',\n",
    "    'val_recall_tier2_majority': 'Recall $T_2$',\n",
    "    'val_recall_tier3_majority': 'Recall $T_3$',\n",
    "    'val_cohen_kappa_tier1_majority': 'Kappa $T_1$',\n",
    "    'val_cohen_kappa_tier2_majority': 'Kappa $T_2$',\n",
    "    'val_cohen_kappa_tier3_majority': 'Kappa $T_3$',\n",
    "}\n",
    "\n",
    "# Function to create a LaTeX table with bold best scores\n",
    "def create_latex_table(df, first_n_metrics=None):\n",
    "    metrics = list(metric_name_mapping.keys())\n",
    "    if first_n_metrics:\n",
    "        metrics = metrics[:first_n_metrics]\n",
    "    \n",
    "    # Determine the best score for each metric\n",
    "    best_scores = {metric: df[f'{metric}_mean'].max() for metric in metrics}\n",
    "    \n",
    "    # Initialize the Texttable object\n",
    "    table = tt.Texttable()\n",
    "    \n",
    "    # Define the header and make headers vertical\n",
    "    headers = ['Metric'] + [f\"{setup} ({row['num_runs']}-fold)\" for idx, row in df.iterrows() for setup in [row['setup']]]\n",
    "    # headers = [f'\\\\rotatebox{{45}}{{{header}}}' for header in headers]\n",
    "\n",
    "    table.header(headers)\n",
    "    \n",
    "    # Set alignment for columns\n",
    "    cols_align = [\"c\"] * len(headers)\n",
    "    cols_align[0] = \"l\"\n",
    "    table.set_cols_align(cols_align)\n",
    "    \n",
    "    # Populate the table with data\n",
    "    for metric in metrics:\n",
    "        row_data = [metric_name_mapping[metric]]\n",
    "        for idx, row in df.iterrows():\n",
    "            mean = row[f'{metric}_mean'] * 100\n",
    "            std = row[f'{metric}_std'] * 100\n",
    "            value = f'{mean:.1f}\\\\% Â± {std:.1f}\\\\%'\n",
    "            if mean == best_scores[metric] * 100:\n",
    "                value = f'\\\\textbf{{{value}}}'\n",
    "            row_data.append(value)\n",
    "        table.add_row(row_data)\n",
    "    \n",
    "    # Generate the LaTeX table\n",
    "    average_epochs_used = df['average_epochs'].iloc[0]\n",
    "    caption_averaged =  f\"averaged over {average_epochs_used} epochs\" if average_epochs_used else \"\"\n",
    "    latex_table = latextable.draw_latex(\n",
    "        table, \n",
    "        caption=f\"Results for experiment {EXPERIMENT_GROUP}. All metrics calculated on field majority during validation phase {caption_averaged}, with mean and std reported. Best scores shown in bold.\", \n",
    "        label=f\"tab:metrics_comparison_{EXPERIMENT_GROUP}\", \n",
    "        use_booktabs=True,\n",
    "        position=\"h\"\n",
    "    )\n",
    "\n",
    "    # Add \\resizebox to the LaTeX table\n",
    "    latex_table = latex_table.replace('\\\\begin{center}', '\\\\begin{center}\\\\resizebox{\\\\textwidth}{!}{')\n",
    "    latex_table = latex_table.replace('\\\\end{center}', '}\\\\end{center}')\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Generate the LaTeX table\n",
    "latex_table = create_latex_table(df, first_n_metrics=6)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "messis-bV8Bs8aq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
